{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Data "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyodbc\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Database credentials\n",
        "server = 'techentjan.database.windows.net'\n",
        "database = 'QAECECRM_jan'\n",
        "username = 'azureml_user'\n",
        "password = 'ElevateLivePro12!'\n",
        "\n",
        "# Connection string\n",
        "connection_string = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};Encrypt=yes\"\n",
        "\n",
        "# Connect to Azure SQL Database\n",
        "try:\n",
        "    conn = pyodbc.connect(connection_string)\n",
        "    print(\"Connection successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Connection successful!\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1740969957532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1740969958657
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"SELECT PresenterId, AgentId, AccountName, OrganizationName, PresenterTypeId, MailingAddress1, MailingAddress2, MailingCity, MailingStateId, MailingZip, MailingCountryId, PhysicalAddress1, PhysicalAddress2, PhysicalCity, PhysicalStateId, PhysicalZip, PhysicalCountryId, PhysicalGeoLatitude, PhysicalGeoLongitude, Notes, IsActive, CreatedDate, CreatedById, UpdatedDate, UpdatedById, ArchiveDate, ParentPresenterId FROM [dbo].[Presenter]\"\n",
        "conn2 = pyodbc.connect(connection_string)\n",
        "df_presenter = pd.read_sql(query1, conn2)\n",
        "df_presenter.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   PresenterId  AgentId                  AccountName OrganizationName  \\\n0            0      281                          ASD             None   \n1            8      107  COLLEGE OF WILLIAM AND MARY    BETA THETA PI   \n2           32      443               WAKE SUPPLY CO             None   \n3           82      435            MARRIOTT/RICHMOND             None   \n4           85      253                    [Unknown]             None   \n\n   PresenterTypeId                               MailingAddress1  \\\n0               99                                          None   \n1               49                          700 UKROP WAY UNIT M   \n2                8  1700 JEFFREY ST                                \n3               99                                          None   \n4               99                                          None   \n\n             MailingAddress2   MailingCity  MailingStateId MailingZip  ...  \\\n0                       None          None             999       None  ...   \n1  COLLEGE OF WILLIAM & MARY  WILLIAMSBURG              46       None  ...   \n2                       None       RALEIGH              28      27610  ...   \n3                       None          None             999       None  ...   \n4                       None          None             999       None  ...   \n\n   PhysicalGeoLatitude PhysicalGeoLongitude  \\\n0                  NaN                  NaN   \n1              37.2458             -76.6970   \n2              35.7455             -78.5467   \n3                  NaN                  NaN   \n4                  NaN                  NaN   \n\n                                               Notes IsActive  CreatedDate  \\\n0  \\r\\n\\r\\n\\r\\n\\r\\nORTH CAROLINA\\r\\nORTH CAROLINA...    False   2016-11-10   \n1                                               None     True   2012-06-04   \n2                                               None    False   2003-12-30   \n3                                               None    False   2012-04-11   \n4                                               None    False   2009-06-12   \n\n  CreatedById             UpdatedDate  UpdatedById  ArchiveDate  \\\n0         281 2022-04-18 14:13:32.130        281.0         None   \n1         107                     NaT          NaN         None   \n2         443 2018-06-02 08:47:55.370     999999.0   2018-06-02   \n3         435 2018-06-02 08:47:55.370     999999.0   2018-06-02   \n4         253 2018-06-02 08:47:55.370     999999.0   2018-06-02   \n\n  ParentPresenterId  \n0                 0  \n1                 0  \n2                 0  \n3                 0  \n4                 0  \n\n[5 rows x 27 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PresenterId</th>\n      <th>AgentId</th>\n      <th>AccountName</th>\n      <th>OrganizationName</th>\n      <th>PresenterTypeId</th>\n      <th>MailingAddress1</th>\n      <th>MailingAddress2</th>\n      <th>MailingCity</th>\n      <th>MailingStateId</th>\n      <th>MailingZip</th>\n      <th>...</th>\n      <th>PhysicalGeoLatitude</th>\n      <th>PhysicalGeoLongitude</th>\n      <th>Notes</th>\n      <th>IsActive</th>\n      <th>CreatedDate</th>\n      <th>CreatedById</th>\n      <th>UpdatedDate</th>\n      <th>UpdatedById</th>\n      <th>ArchiveDate</th>\n      <th>ParentPresenterId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>281</td>\n      <td>ASD</td>\n      <td>None</td>\n      <td>99</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>999</td>\n      <td>None</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>\\r\\n\\r\\n\\r\\n\\r\\nORTH CAROLINA\\r\\nORTH CAROLINA...</td>\n      <td>False</td>\n      <td>2016-11-10</td>\n      <td>281</td>\n      <td>2022-04-18 14:13:32.130</td>\n      <td>281.0</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>107</td>\n      <td>COLLEGE OF WILLIAM AND MARY</td>\n      <td>BETA THETA PI</td>\n      <td>49</td>\n      <td>700 UKROP WAY UNIT M</td>\n      <td>COLLEGE OF WILLIAM &amp; MARY</td>\n      <td>WILLIAMSBURG</td>\n      <td>46</td>\n      <td>None</td>\n      <td>...</td>\n      <td>37.2458</td>\n      <td>-76.6970</td>\n      <td>None</td>\n      <td>True</td>\n      <td>2012-06-04</td>\n      <td>107</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>443</td>\n      <td>WAKE SUPPLY CO</td>\n      <td>None</td>\n      <td>8</td>\n      <td>1700 JEFFREY ST</td>\n      <td>None</td>\n      <td>RALEIGH</td>\n      <td>28</td>\n      <td>27610</td>\n      <td>...</td>\n      <td>35.7455</td>\n      <td>-78.5467</td>\n      <td>None</td>\n      <td>False</td>\n      <td>2003-12-30</td>\n      <td>443</td>\n      <td>2018-06-02 08:47:55.370</td>\n      <td>999999.0</td>\n      <td>2018-06-02</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>82</td>\n      <td>435</td>\n      <td>MARRIOTT/RICHMOND</td>\n      <td>None</td>\n      <td>99</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>999</td>\n      <td>None</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>False</td>\n      <td>2012-04-11</td>\n      <td>435</td>\n      <td>2018-06-02 08:47:55.370</td>\n      <td>999999.0</td>\n      <td>2018-06-02</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>85</td>\n      <td>253</td>\n      <td>[Unknown]</td>\n      <td>None</td>\n      <td>99</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>999</td>\n      <td>None</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>False</td>\n      <td>2009-06-12</td>\n      <td>253</td>\n      <td>2018-06-02 08:47:55.370</td>\n      <td>999999.0</td>\n      <td>2018-06-02</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1740969962910
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"SELECT GenreTypeId, Name, IsActive FROM [dbo].LuGenreType\"\n",
        "df_genre = pd.read_sql(query2, conn)\n",
        "df_genre.head()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "   GenreTypeId                     Name  IsActive\n0            1  A Cappella/Vocal Groups      True\n1            2                 Acrobats      True\n2            3                  African      True\n3            4       Animal/Circus Acts      True\n4            5             Audio Visual      True",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GenreTypeId</th>\n      <th>Name</th>\n      <th>IsActive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A Cappella/Vocal Groups</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Acrobats</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>African</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Animal/Circus Acts</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Audio Visual</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1740969963027
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"\"\"\n",
        "SELECT \n",
        "    ArtistId,\n",
        "    Name,\n",
        "    MailingCountryId,\n",
        "    PhysicalAddressCity,\n",
        "    PhysicalAddressStateId,\n",
        "    PhysicalGeoLatitude,\n",
        "    PhysicalGeoLongitude,\n",
        "    IsActive,\n",
        "    IsExclusive,\n",
        "    ExclusiveStartDate,\n",
        "    NationalNetPriceLowerBound,\n",
        "    NationalNetPriceUpperBound,\n",
        "    NationalOneOffPrice,\n",
        "    CreatedDate,\n",
        "    UpdatedDate,\n",
        "    IsNational,\n",
        "    IsNotParticipating\n",
        "FROM Artist;\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query and load data into a Pandas DataFrame\n",
        "artist_df = pd.read_sql(query3, conn)\n",
        "artist_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "   ArtistId                 Name  MailingCountryId PhysicalAddressCity  \\\n0         2                    O               1.0            RICHMOND   \n1         3        GROOVE DELUXE               1.0           ROCK HILL   \n2         4  QUINTON PARKER BAND               1.0             ASHLAND   \n3         5  BILL BOLEN BAND (4)               1.0         CHAPEL HILL   \n4         6       88 KEYS WILSON               1.0     CHARLOTTESVILLE   \n\n   PhysicalAddressStateId  PhysicalGeoLatitude  PhysicalGeoLongitude  \\\n0                    46.0              37.5770              -77.5388   \n1                    41.0              34.8867              -81.0208   \n2                    46.0              37.7596              -77.4822   \n3                    28.0              35.9672              -79.0444   \n4                    46.0              38.0884              -78.5562   \n\n   IsActive  IsExclusive ExclusiveStartDate  NationalNetPriceLowerBound  \\\n0      True        False                NaT                         NaN   \n1      True        False                NaT                         NaN   \n2      True        False                NaT                         NaN   \n3      True        False                NaT                         NaN   \n4      True        False                NaT                         NaN   \n\n   NationalNetPriceUpperBound  NationalOneOffPrice             CreatedDate  \\\n0                         NaN                  NaN 2018-06-02 04:05:01.677   \n1                         NaN                  NaN 2018-06-02 04:05:01.677   \n2                         NaN                  NaN 2018-06-02 04:05:01.677   \n3                         NaN                  NaN 2018-06-02 04:05:01.683   \n4                         NaN                  NaN 2018-06-02 04:05:01.683   \n\n              UpdatedDate  IsNational  IsNotParticipating  \n0                     NaT       False               False  \n1                     NaT       False               False  \n2                     NaT       False               False  \n3 2018-09-19 15:21:38.730       False               False  \n4 2019-11-18 15:16:17.807       False               False  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArtistId</th>\n      <th>Name</th>\n      <th>MailingCountryId</th>\n      <th>PhysicalAddressCity</th>\n      <th>PhysicalAddressStateId</th>\n      <th>PhysicalGeoLatitude</th>\n      <th>PhysicalGeoLongitude</th>\n      <th>IsActive</th>\n      <th>IsExclusive</th>\n      <th>ExclusiveStartDate</th>\n      <th>NationalNetPriceLowerBound</th>\n      <th>NationalNetPriceUpperBound</th>\n      <th>NationalOneOffPrice</th>\n      <th>CreatedDate</th>\n      <th>UpdatedDate</th>\n      <th>IsNational</th>\n      <th>IsNotParticipating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>O</td>\n      <td>1.0</td>\n      <td>RICHMOND</td>\n      <td>46.0</td>\n      <td>37.5770</td>\n      <td>-77.5388</td>\n      <td>True</td>\n      <td>False</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2018-06-02 04:05:01.677</td>\n      <td>NaT</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>GROOVE DELUXE</td>\n      <td>1.0</td>\n      <td>ROCK HILL</td>\n      <td>41.0</td>\n      <td>34.8867</td>\n      <td>-81.0208</td>\n      <td>True</td>\n      <td>False</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2018-06-02 04:05:01.677</td>\n      <td>NaT</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>QUINTON PARKER BAND</td>\n      <td>1.0</td>\n      <td>ASHLAND</td>\n      <td>46.0</td>\n      <td>37.7596</td>\n      <td>-77.4822</td>\n      <td>True</td>\n      <td>False</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2018-06-02 04:05:01.677</td>\n      <td>NaT</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>BILL BOLEN BAND (4)</td>\n      <td>1.0</td>\n      <td>CHAPEL HILL</td>\n      <td>28.0</td>\n      <td>35.9672</td>\n      <td>-79.0444</td>\n      <td>True</td>\n      <td>False</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2018-06-02 04:05:01.683</td>\n      <td>2018-09-19 15:21:38.730</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>88 KEYS WILSON</td>\n      <td>1.0</td>\n      <td>CHARLOTTESVILLE</td>\n      <td>46.0</td>\n      <td>38.0884</td>\n      <td>-78.5562</td>\n      <td>True</td>\n      <td>False</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2018-06-02 04:05:01.683</td>\n      <td>2019-11-18 15:16:17.807</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1740969964020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query4 = \"SELECT ActTypeId, Name, IsActive FROM [dbo].LuActType\"\n",
        "df_act = pd.read_sql(query4, conn)\n",
        "df_act.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "   ActTypeId           Name  IsActive\n0          1          Bands      True\n1          2      Classical      True\n2          3      Comedians      True\n3          4            DJs      True\n4          5  International      True",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ActTypeId</th>\n      <th>Name</th>\n      <th>IsActive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Bands</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Classical</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Comedians</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>DJs</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>International</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1740969966227
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query5 = \"SELECT * FROM [dbo].ArtistFeedback\"\n",
        "df_feedback = pd.read_sql(query5, conn)\n",
        "df_feedback.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "   ArtistFeedbackId  ArtistId  PresenterPortalId  ContractId  IsNegative  \\\n0                 1      3061                  1      100304       False   \n1                 2       918                  2      103526       False   \n2                 3       154                  3      104617       False   \n3                 4        55                  4      105392       False   \n4                 5        32                  5      105486       False   \n\n  ReviewDate                                           Feedback  AgentId  \\\n0 2001-07-19  THE BREEZE BAND ARE THE BEST. THEY ARE NOT ONL...      NaN   \n1 1991-01-21                               EVRYTHING WENT GREAT      NaN   \n2 1991-02-15                                      BKD MIRAGE 91      NaN   \n3 1991-01-09                                    BKD MAINSTAY 91      NaN   \n4 1991-01-09                       BAND PLAYS REGULARLY AT CLUB      NaN   \n\n  Response ResponseDate         CreatedDate  CreatedById UpdatedDate  \\\n0     None          NaT 2006-06-07 09:03:58            0         NaT   \n1     None          NaT 2006-06-07 05:42:43            0         NaT   \n2     None          NaT 2006-06-07 02:25:48            0         NaT   \n3     None          NaT 2006-06-07 00:39:30            0         NaT   \n4     None          NaT 2006-06-07 00:19:13            0         NaT   \n\n   UpdatedById  \n0          NaN  \n1          NaN  \n2          NaN  \n3          NaN  \n4          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArtistFeedbackId</th>\n      <th>ArtistId</th>\n      <th>PresenterPortalId</th>\n      <th>ContractId</th>\n      <th>IsNegative</th>\n      <th>ReviewDate</th>\n      <th>Feedback</th>\n      <th>AgentId</th>\n      <th>Response</th>\n      <th>ResponseDate</th>\n      <th>CreatedDate</th>\n      <th>CreatedById</th>\n      <th>UpdatedDate</th>\n      <th>UpdatedById</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3061</td>\n      <td>1</td>\n      <td>100304</td>\n      <td>False</td>\n      <td>2001-07-19</td>\n      <td>THE BREEZE BAND ARE THE BEST. THEY ARE NOT ONL...</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>2006-06-07 09:03:58</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>918</td>\n      <td>2</td>\n      <td>103526</td>\n      <td>False</td>\n      <td>1991-01-21</td>\n      <td>EVRYTHING WENT GREAT</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>2006-06-07 05:42:43</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>154</td>\n      <td>3</td>\n      <td>104617</td>\n      <td>False</td>\n      <td>1991-02-15</td>\n      <td>BKD MIRAGE 91</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>2006-06-07 02:25:48</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>55</td>\n      <td>4</td>\n      <td>105392</td>\n      <td>False</td>\n      <td>1991-01-09</td>\n      <td>BKD MAINSTAY 91</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>2006-06-07 00:39:30</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>32</td>\n      <td>5</td>\n      <td>105486</td>\n      <td>False</td>\n      <td>1991-01-09</td>\n      <td>BAND PLAYS REGULARLY AT CLUB</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>2006-06-07 00:19:13</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1740969967766
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query6 = \"SELECT * FROM [dbo].BlueCardArtist\"\n",
        "df_bluecardartist = pd.read_sql(query6, conn)\n",
        "df_bluecardartist.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "   BlueCardArtistId  BlueCardId  ArtistId   Gross  Net      Notes  IsDeleted  \\\n0                 1           0       136  3250.0  0.0       None      False   \n1                 2           0       296  7750.0  0.0  w/ female      False   \n2                 3           0     11183     0.0  0.0       None      False   \n3                 4           0     15104     0.0  0.0       None      False   \n4                 5           0     15104     0.0  0.0       None      False   \n\n              CreatedDate  CreatedById UpdatedDate  UpdatedById  \n0 2018-06-02 04:06:42.950            0         NaT          NaN  \n1 2018-06-02 04:06:42.950            0         NaT          NaN  \n2 2018-06-02 04:06:42.950            0         NaT          NaN  \n3 2018-06-02 04:06:42.950            0         NaT          NaN  \n4 2018-06-02 04:06:42.950            0         NaT          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BlueCardArtistId</th>\n      <th>BlueCardId</th>\n      <th>ArtistId</th>\n      <th>Gross</th>\n      <th>Net</th>\n      <th>Notes</th>\n      <th>IsDeleted</th>\n      <th>CreatedDate</th>\n      <th>CreatedById</th>\n      <th>UpdatedDate</th>\n      <th>UpdatedById</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>136</td>\n      <td>3250.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>False</td>\n      <td>2018-06-02 04:06:42.950</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>296</td>\n      <td>7750.0</td>\n      <td>0.0</td>\n      <td>w/ female</td>\n      <td>False</td>\n      <td>2018-06-02 04:06:42.950</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>11183</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>False</td>\n      <td>2018-06-02 04:06:42.950</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>15104</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>False</td>\n      <td>2018-06-02 04:06:42.950</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>15104</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>False</td>\n      <td>2018-06-02 04:06:42.950</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1740969976639
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query7 = '''SELECT \n",
        "    VenueId,\n",
        "    AgentId,\n",
        "    Name,\n",
        "    VenueSettingId,\n",
        "    IsSettingCovered,\n",
        "    MailingAddress1,\n",
        "    MailingAddress2,\n",
        "    MailingCity,\n",
        "    MailingStateId,\n",
        "    MailingZip,\n",
        "    MailingCountryId,\n",
        "    PhysicalAddress1,\n",
        "    PhysicalAddress2,\n",
        "    PhysicalCity,\n",
        "    PhysicalStateId,\n",
        "    PhysicalZip,\n",
        "    PhysicalCountryId,\n",
        "    Notes,\n",
        "    Capacity,\n",
        "    IsActive,\n",
        "    PresenterId,\n",
        "    CreatedDate,\n",
        "    CreatedById,\n",
        "    UpdatedDate,\n",
        "    UpdatedById,\n",
        "    ArchiveDate,\n",
        "    VenueManagerId,\n",
        "    NotifyForLead,\n",
        "    NotifyForBC,\n",
        "    NotifyForContract,\n",
        "    NotifyForApproval\n",
        "FROM [dbo].Venue'''\n",
        "df_venue = pd.read_sql(query7, conn)\n",
        "df_venue.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "   VenueId  AgentId                               Name  VenueSettingId  \\\n0        1    141.0                     HILTON ATLANTA               3   \n1        2    141.0           MARRIOTT MARQUIS ATLANTA               3   \n2        3    430.0  Moreland Landing @ Palmetto Bluff               2   \n3        4    141.0        EVERGREEN CONFERENCE CENTER               3   \n4        5    141.0              MERCEDES-BENZ STADIUM               1   \n\n   IsSettingCovered                          MailingAddress1  \\\n0             False                  255 COURTLAND STREET NE   \n1             False              265 PEACHTREE CENTER AVENUE   \n2              True                            Moreland Road   \n3             False              EVERGREEN CONFERENCE CENTER   \n4             False  1414 ANDREW YOUNG INTERNATIONAL BLVD NW   \n\n    MailingAddress2     MailingCity  MailingStateId MailingZip  ...  \\\n0                           ATLANTA              11      30303  ...   \n1                           ATLANTA              11      30303  ...   \n2                          BLUFFTON              41      29910  ...   \n3  1 LAKEVIEW DRIVE  STONE MOUNTAIN              11      30086  ...   \n4                           ATLANTA              11      30313  ...   \n\n              CreatedDate CreatedById             UpdatedDate UpdatedById  \\\n0 2018-06-04 11:42:41.587         141                     NaT         NaN   \n1 2018-06-04 11:46:28.407         141                     NaT         NaN   \n2 2018-06-04 11:52:10.490         445 2023-01-25 09:12:27.047       182.0   \n3 2018-06-04 11:55:11.247         141                     NaT         NaN   \n4 2018-06-04 11:56:29.607         141 2020-02-05 13:55:16.493       141.0   \n\n   ArchiveDate VenueManagerId  NotifyForLead NotifyForBC  NotifyForContract  \\\n0         None            NaN           None        None               None   \n1         None            NaN           None        None               None   \n2         None            NaN           None        None               None   \n3         None            NaN           None        None               None   \n4         None            NaN           None        None               None   \n\n   NotifyForApproval  \n0               None  \n1               None  \n2               None  \n3               None  \n4               None  \n\n[5 rows x 31 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VenueId</th>\n      <th>AgentId</th>\n      <th>Name</th>\n      <th>VenueSettingId</th>\n      <th>IsSettingCovered</th>\n      <th>MailingAddress1</th>\n      <th>MailingAddress2</th>\n      <th>MailingCity</th>\n      <th>MailingStateId</th>\n      <th>MailingZip</th>\n      <th>...</th>\n      <th>CreatedDate</th>\n      <th>CreatedById</th>\n      <th>UpdatedDate</th>\n      <th>UpdatedById</th>\n      <th>ArchiveDate</th>\n      <th>VenueManagerId</th>\n      <th>NotifyForLead</th>\n      <th>NotifyForBC</th>\n      <th>NotifyForContract</th>\n      <th>NotifyForApproval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>141.0</td>\n      <td>HILTON ATLANTA</td>\n      <td>3</td>\n      <td>False</td>\n      <td>255 COURTLAND STREET NE</td>\n      <td></td>\n      <td>ATLANTA</td>\n      <td>11</td>\n      <td>30303</td>\n      <td>...</td>\n      <td>2018-06-04 11:42:41.587</td>\n      <td>141</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>141.0</td>\n      <td>MARRIOTT MARQUIS ATLANTA</td>\n      <td>3</td>\n      <td>False</td>\n      <td>265 PEACHTREE CENTER AVENUE</td>\n      <td></td>\n      <td>ATLANTA</td>\n      <td>11</td>\n      <td>30303</td>\n      <td>...</td>\n      <td>2018-06-04 11:46:28.407</td>\n      <td>141</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>430.0</td>\n      <td>Moreland Landing @ Palmetto Bluff</td>\n      <td>2</td>\n      <td>True</td>\n      <td>Moreland Road</td>\n      <td></td>\n      <td>BLUFFTON</td>\n      <td>41</td>\n      <td>29910</td>\n      <td>...</td>\n      <td>2018-06-04 11:52:10.490</td>\n      <td>445</td>\n      <td>2023-01-25 09:12:27.047</td>\n      <td>182.0</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>141.0</td>\n      <td>EVERGREEN CONFERENCE CENTER</td>\n      <td>3</td>\n      <td>False</td>\n      <td>EVERGREEN CONFERENCE CENTER</td>\n      <td>1 LAKEVIEW DRIVE</td>\n      <td>STONE MOUNTAIN</td>\n      <td>11</td>\n      <td>30086</td>\n      <td>...</td>\n      <td>2018-06-04 11:55:11.247</td>\n      <td>141</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>141.0</td>\n      <td>MERCEDES-BENZ STADIUM</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1414 ANDREW YOUNG INTERNATIONAL BLVD NW</td>\n      <td></td>\n      <td>ATLANTA</td>\n      <td>11</td>\n      <td>30313</td>\n      <td>...</td>\n      <td>2018-06-04 11:56:29.607</td>\n      <td>141</td>\n      <td>2020-02-05 13:55:16.493</td>\n      <td>141.0</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1740969976771
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tables=[df_presenter,df_genre,artist_df,df_venue,df_genre,df_bluecardartist,df_feedback]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1740700676553
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df in tables:\n",
        "    print(df.isnull().sum())\n",
        "    print(\"-\" * 50)  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PresenterId                 0\nAgentId                     0\nAccountName                 0\nOrganizationName        39190\nPresenterTypeId             0\nMailingAddress1          3352\nMailingAddress2         16547\nMailingCity              2062\nMailingStateId              0\nMailingZip               4520\nMailingCountryId            0\nPhysicalAddress1         3352\nPhysicalAddress2        16547\nPhysicalCity             2062\nPhysicalStateId             0\nPhysicalZip              4520\nPhysicalCountryId           0\nPhysicalGeoLatitude      3930\nPhysicalGeoLongitude     3930\nNotes                   54001\nIsActive                    0\nCreatedDate                 0\nCreatedById                 0\nUpdatedDate             45937\nUpdatedById             45937\nArchiveDate             66975\nParentPresenterId           0\ndtype: int64\n--------------------------------------------------\nGenreTypeId    0\nName           0\nIsActive       0\ndtype: int64\n--------------------------------------------------\nArtistId                          0\nName                              0\nMailingCountryId               2655\nPhysicalAddressCity            3577\nPhysicalAddressStateId         3530\nPhysicalGeoLatitude            3617\nPhysicalGeoLongitude           3617\nIsActive                          0\nIsExclusive                       0\nExclusiveStartDate            23397\nNationalNetPriceLowerBound    21583\nNationalNetPriceUpperBound    21584\nNationalOneOffPrice           21569\nCreatedDate                       0\nUpdatedDate                   10838\nIsNational                        0\nIsNotParticipating                0\ndtype: int64\n--------------------------------------------------\nVenueId                 0\nAgentId               837\nName                    0\nVenueSettingId          0\nIsSettingCovered        0\nMailingAddress1         0\nMailingAddress2         0\nMailingCity             0\nMailingStateId          0\nMailingZip              0\nMailingCountryId        0\nPhysicalAddress1        0\nPhysicalAddress2        0\nPhysicalCity            0\nPhysicalStateId         0\nPhysicalZip             0\nPhysicalCountryId       0\nNotes                   0\nCapacity             2827\nIsActive                0\nPresenterId          1314\nCreatedDate             0\nCreatedById             0\nUpdatedDate          2259\nUpdatedById          2259\nArchiveDate          3490\nVenueManagerId       3499\nNotifyForLead        3499\nNotifyForBC          3499\nNotifyForContract    3499\nNotifyForApproval    3499\ndtype: int64\n--------------------------------------------------\nGenreTypeId    0\nName           0\nIsActive       0\ndtype: int64\n--------------------------------------------------\nBlueCardArtistId         0\nBlueCardId               0\nArtistId                 0\nGross                10071\nNet                 366233\nNotes               394165\nIsDeleted                0\nCreatedDate              0\nCreatedById              0\nUpdatedDate         496952\nUpdatedById         496952\ndtype: int64\n--------------------------------------------------\nArtistFeedbackId         0\nArtistId                 0\nPresenterPortalId        0\nContractId               0\nIsNegative               0\nReviewDate               0\nFeedback                 0\nAgentId              47203\nResponse             44397\nResponseDate         47203\nCreatedDate              0\nCreatedById              0\nUpdatedDate          47229\nUpdatedById          47229\ndtype: int64\n--------------------------------------------------\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1740700676616
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tables = {\n",
        "    \"df_presenter\": df_presenter,\n",
        "    \"df_genre\": df_genre,\n",
        "    \"artist_df\": artist_df,\n",
        "    \"df_venue\": df_venue,\n",
        "    \"df_bluecardartist\": df_bluecardartist,\n",
        "    \"df_feedback\": df_feedback\n",
        "}\n",
        "\n",
        "for name, df in tables.items():\n",
        "    print(f\"Missing Values Percentage in {name}:\")\n",
        "    missing_percentage = (df.isnull().sum() / len(df)) \n",
        "    print(missing_percentage)\n",
        "    print(\"-\" * 50)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Missing Values Percentage in df_presenter:\nPresenterId             0.000000\nAgentId                 0.000000\nAccountName             0.000000\nOrganizationName        0.435875\nPresenterTypeId         0.000000\nMailingAddress1         0.037281\nMailingAddress2         0.184038\nMailingCity             0.022934\nMailingStateId          0.000000\nMailingZip              0.050272\nMailingCountryId        0.000000\nPhysicalAddress1        0.037281\nPhysicalAddress2        0.184038\nPhysicalCity            0.022934\nPhysicalStateId         0.000000\nPhysicalZip             0.050272\nPhysicalCountryId       0.000000\nPhysicalGeoLatitude     0.043710\nPhysicalGeoLongitude    0.043710\nNotes                   0.600605\nIsActive                0.000000\nCreatedDate             0.000000\nCreatedById             0.000000\nUpdatedDate             0.510916\nUpdatedById             0.510916\nArchiveDate             0.744903\nParentPresenterId       0.000000\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in df_genre:\nGenreTypeId    0.0\nName           0.0\nIsActive       0.0\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in artist_df:\nArtistId                      0.000000\nName                          0.000000\nMailingCountryId              0.112548\nPhysicalAddressCity           0.151632\nPhysicalAddressStateId        0.149640\nPhysicalGeoLatitude           0.153328\nPhysicalGeoLongitude          0.153328\nIsActive                      0.000000\nIsExclusive                   0.000000\nExclusiveStartDate            0.991819\nNationalNetPriceLowerBound    0.914922\nNationalNetPriceUpperBound    0.914964\nNationalOneOffPrice           0.914328\nCreatedDate                   0.000000\nUpdatedDate                   0.459432\nIsNational                    0.000000\nIsNotParticipating            0.000000\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in df_venue:\nVenueId              0.000000\nAgentId              0.239006\nName                 0.000000\nVenueSettingId       0.000000\nIsSettingCovered     0.000000\nMailingAddress1      0.000000\nMailingAddress2      0.000000\nMailingCity          0.000000\nMailingStateId       0.000000\nMailingZip           0.000000\nMailingCountryId     0.000000\nPhysicalAddress1     0.000000\nPhysicalAddress2     0.000000\nPhysicalCity         0.000000\nPhysicalStateId      0.000000\nPhysicalZip          0.000000\nPhysicalCountryId    0.000000\nNotes                0.000000\nCapacity             0.807253\nIsActive             0.000000\nPresenterId          0.375214\nCreatedDate          0.000000\nCreatedById          0.000000\nUpdatedDate          0.645060\nUpdatedById          0.645060\nArchiveDate          0.996573\nVenueManagerId       0.999143\nNotifyForLead        0.999143\nNotifyForBC          0.999143\nNotifyForContract    0.999143\nNotifyForApproval    0.999143\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in df_bluecardartist:\nBlueCardArtistId    0.000000\nBlueCardId          0.000000\nArtistId            0.000000\nGross               0.012142\nNet                 0.441557\nNotes               0.475234\nIsDeleted           0.000000\nCreatedDate         0.000000\nCreatedById         0.000000\nUpdatedDate         0.599161\nUpdatedById         0.599161\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in df_feedback:\nArtistFeedbackId     0.000000\nArtistId             0.000000\nPresenterPortalId    0.000000\nContractId           0.000000\nIsNegative           0.000000\nReviewDate           0.000000\nFeedback             0.000000\nAgentId              0.995214\nResponse             0.936053\nResponseDate         0.995214\nCreatedDate          0.000000\nCreatedById          0.000000\nUpdatedDate          0.995762\nUpdatedById          0.995762\ndtype: float64\n--------------------------------------------------\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1740700676806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "threshold = 0.5\n",
        "\n",
        "\n",
        "tables = {\n",
        "    \"df_presenter\": df_presenter,\n",
        "    \"df_genre\": df_genre,\n",
        "    \"artist_df\": artist_df,\n",
        "    \"df_venue\": df_venue,\n",
        "    \"df_bluecardartist\": df_bluecardartist,\n",
        "    \"df_feedback\": df_feedback\n",
        "}\n",
        "\n",
        "\n",
        "for name, df in tables.items():\n",
        "    missing_ratio = df.isnull().sum() / len(df)  # Calculate missing percentage\n",
        "    columns_to_drop = missing_ratio[missing_ratio > threshold].index  # Identify columns > 50% missing\n",
        "    df.drop(columns=columns_to_drop, inplace=True)  # Drop columns\n",
        "    print(f\"Dropped columns from {name}: {list(columns_to_drop)}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dropped columns from df_presenter: ['Notes', 'UpdatedDate', 'UpdatedById', 'ArchiveDate']\n--------------------------------------------------\nDropped columns from df_genre: []\n--------------------------------------------------\nDropped columns from artist_df: ['ExclusiveStartDate', 'NationalNetPriceLowerBound', 'NationalNetPriceUpperBound', 'NationalOneOffPrice']\n--------------------------------------------------\nDropped columns from df_venue: ['Capacity', 'UpdatedDate', 'UpdatedById', 'ArchiveDate', 'VenueManagerId', 'NotifyForLead', 'NotifyForBC', 'NotifyForContract', 'NotifyForApproval']\n--------------------------------------------------\nDropped columns from df_bluecardartist: ['UpdatedDate', 'UpdatedById']\n--------------------------------------------------\nDropped columns from df_feedback: ['AgentId', 'Response', 'ResponseDate', 'UpdatedDate', 'UpdatedById']\n--------------------------------------------------\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1740700676893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tables = {\n",
        "    \"df_presenter\": df_presenter,\n",
        "    \"df_genre\": df_genre,\n",
        "    \"artist_df\": artist_df,\n",
        "    \"df_venue\": df_venue,\n",
        "    \"df_bluecardartist\": df_bluecardartist,\n",
        "    \"df_feedback\": df_feedback\n",
        "}\n",
        "\n",
        "for name, df in tables.items():\n",
        "    print(f\"Missing Values Percentage in {name}:\")\n",
        "    missing_percentage = (df.isnull().sum() / len(df)) \n",
        "    print(missing_percentage)\n",
        "    print(\"-\" * 50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Missing Values Percentage in df_presenter:\nPresenterId             0.000000\nAgentId                 0.000000\nAccountName             0.000000\nOrganizationName        0.435875\nPresenterTypeId         0.000000\nMailingAddress1         0.037281\nMailingAddress2         0.184038\nMailingCity             0.022934\nMailingStateId          0.000000\nMailingZip              0.050272\nMailingCountryId        0.000000\nPhysicalAddress1        0.037281\nPhysicalAddress2        0.184038\nPhysicalCity            0.022934\nPhysicalStateId         0.000000\nPhysicalZip             0.050272\nPhysicalCountryId       0.000000\nPhysicalGeoLatitude     0.043710\nPhysicalGeoLongitude    0.043710\nIsActive                0.000000\nCreatedDate             0.000000\nCreatedById             0.000000\nParentPresenterId       0.000000\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in df_genre:\nGenreTypeId    0.0\nName           0.0\nIsActive       0.0\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in artist_df:\nArtistId                  0.000000\nName                      0.000000\nMailingCountryId          0.112548\nPhysicalAddressCity       0.151632\nPhysicalAddressStateId    0.149640\nPhysicalGeoLatitude       0.153328\nPhysicalGeoLongitude      0.153328\nIsActive                  0.000000\nIsExclusive               0.000000\nCreatedDate               0.000000\nUpdatedDate               0.459432\nIsNational                0.000000\nIsNotParticipating        0.000000\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in df_venue:\nVenueId              0.000000\nAgentId              0.239006\nName                 0.000000\nVenueSettingId       0.000000\nIsSettingCovered     0.000000\nMailingAddress1      0.000000\nMailingAddress2      0.000000\nMailingCity          0.000000\nMailingStateId       0.000000\nMailingZip           0.000000\nMailingCountryId     0.000000\nPhysicalAddress1     0.000000\nPhysicalAddress2     0.000000\nPhysicalCity         0.000000\nPhysicalStateId      0.000000\nPhysicalZip          0.000000\nPhysicalCountryId    0.000000\nNotes                0.000000\nIsActive             0.000000\nPresenterId          0.375214\nCreatedDate          0.000000\nCreatedById          0.000000\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in df_bluecardartist:\nBlueCardArtistId    0.000000\nBlueCardId          0.000000\nArtistId            0.000000\nGross               0.012142\nNet                 0.441557\nNotes               0.475234\nIsDeleted           0.000000\nCreatedDate         0.000000\nCreatedById         0.000000\ndtype: float64\n--------------------------------------------------\nMissing Values Percentage in df_feedback:\nArtistFeedbackId     0.0\nArtistId             0.0\nPresenterPortalId    0.0\nContractId           0.0\nIsNegative           0.0\nReviewDate           0.0\nFeedback             0.0\nCreatedDate          0.0\nCreatedById          0.0\ndtype: float64\n--------------------------------------------------\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1740700677026
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to impute missing values\n",
        "def impute_missing_values(df):\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == \"object\":  \n",
        "            df[col].fillna(\"Unknown\", inplace=True)\n",
        "        elif df[col].dtype in [\"int64\", \"float64\"]:  \n",
        "            if df[col].nunique() < 10:  \n",
        "                df[col].fillna(df[col].mode()[0], inplace=True)  \n",
        "            else:\n",
        "                df[col].fillna(df[col].median(), inplace=True)  \n",
        "        elif np.issubdtype(df[col].dtype, np.datetime64):  \n",
        "            df[col].fillna(df[col].min(), inplace=True)  \n",
        "        elif df[col].dtype == \"bool\":  \n",
        "            df[col].fillna(False, inplace=True)  \n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1740700677092
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply imputation to all DataFrames\n",
        "for name, df in tables.items():\n",
        "    tables[name] = impute_missing_values(df)\n",
        "    print(f\"Imputed missing values in {name}\")\n",
        "\n",
        "# Verify no missing values\n",
        "for name, df in tables.items():\n",
        "    print(f\"Remaining missing values in {name}:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"-\" * 50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Imputed missing values in df_presenter\nImputed missing values in df_genre\nImputed missing values in artist_df\nImputed missing values in df_venue\nImputed missing values in df_bluecardartist\nImputed missing values in df_feedback\nRemaining missing values in df_presenter:\nPresenterId             0\nAgentId                 0\nAccountName             0\nOrganizationName        0\nPresenterTypeId         0\nMailingAddress1         0\nMailingAddress2         0\nMailingCity             0\nMailingStateId          0\nMailingZip              0\nMailingCountryId        0\nPhysicalAddress1        0\nPhysicalAddress2        0\nPhysicalCity            0\nPhysicalStateId         0\nPhysicalZip             0\nPhysicalCountryId       0\nPhysicalGeoLatitude     0\nPhysicalGeoLongitude    0\nIsActive                0\nCreatedDate             0\nCreatedById             0\nParentPresenterId       0\ndtype: int64\n--------------------------------------------------\nRemaining missing values in df_genre:\nGenreTypeId    0\nName           0\nIsActive       0\ndtype: int64\n--------------------------------------------------\nRemaining missing values in artist_df:\nArtistId                  0\nName                      0\nMailingCountryId          0\nPhysicalAddressCity       0\nPhysicalAddressStateId    0\nPhysicalGeoLatitude       0\nPhysicalGeoLongitude      0\nIsActive                  0\nIsExclusive               0\nCreatedDate               0\nUpdatedDate               0\nIsNational                0\nIsNotParticipating        0\ndtype: int64\n--------------------------------------------------\nRemaining missing values in df_venue:\nVenueId              0\nAgentId              0\nName                 0\nVenueSettingId       0\nIsSettingCovered     0\nMailingAddress1      0\nMailingAddress2      0\nMailingCity          0\nMailingStateId       0\nMailingZip           0\nMailingCountryId     0\nPhysicalAddress1     0\nPhysicalAddress2     0\nPhysicalCity         0\nPhysicalStateId      0\nPhysicalZip          0\nPhysicalCountryId    0\nNotes                0\nIsActive             0\nPresenterId          0\nCreatedDate          0\nCreatedById          0\ndtype: int64\n--------------------------------------------------\nRemaining missing values in df_bluecardartist:\nBlueCardArtistId    0\nBlueCardId          0\nArtistId            0\nGross               0\nNet                 0\nNotes               0\nIsDeleted           0\nCreatedDate         0\nCreatedById         0\ndtype: int64\n--------------------------------------------------\nRemaining missing values in df_feedback:\nArtistFeedbackId     0\nArtistId             0\nPresenterPortalId    0\nContractId           0\nIsNegative           0\nReviewDate           0\nFeedback             0\nCreatedDate          0\nCreatedById          0\ndtype: int64\n--------------------------------------------------\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1740700677543
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in tables.items():\n",
        "    print(f\"The head of {name} is:\\n{df.head()}\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The head of df_presenter is:\n   PresenterId  AgentId                  AccountName OrganizationName  \\\n0            0      281                          ASD          Unknown   \n1            8      107  COLLEGE OF WILLIAM AND MARY    BETA THETA PI   \n2           32      443               WAKE SUPPLY CO          Unknown   \n3           82      435            MARRIOTT/RICHMOND          Unknown   \n4           85      253                    [Unknown]          Unknown   \n\n   PresenterTypeId                               MailingAddress1  \\\n0               99                                       Unknown   \n1               49                          700 UKROP WAY UNIT M   \n2                8  1700 JEFFREY ST                                \n3               99                                       Unknown   \n4               99                                       Unknown   \n\n             MailingAddress2   MailingCity  MailingStateId MailingZip  ...  \\\n0                    Unknown       Unknown             999    Unknown  ...   \n1  COLLEGE OF WILLIAM & MARY  WILLIAMSBURG              46    Unknown  ...   \n2                    Unknown       RALEIGH              28      27610  ...   \n3                    Unknown       Unknown             999    Unknown  ...   \n4                    Unknown       Unknown             999    Unknown  ...   \n\n   PhysicalCity PhysicalStateId PhysicalZip PhysicalCountryId  \\\n0       Unknown             999     Unknown                 1   \n1  WILLIAMSBURG              46     Unknown                 1   \n2       RALEIGH              28       27610                 1   \n3       Unknown             999     Unknown                 1   \n4       Unknown             999     Unknown                 1   \n\n   PhysicalGeoLatitude PhysicalGeoLongitude  IsActive  CreatedDate  \\\n0              35.7373           -80.770107     False   2016-11-10   \n1              37.2458           -76.697000      True   2012-06-04   \n2              35.7455           -78.546700     False   2003-12-30   \n3              35.7373           -80.770107     False   2012-04-11   \n4              35.7373           -80.770107     False   2009-06-12   \n\n   CreatedById  ParentPresenterId  \n0          281                  0  \n1          107                  0  \n2          443                  0  \n3          435                  0  \n4          253                  0  \n\n[5 rows x 23 columns]\n\nThe head of df_genre is:\n   GenreTypeId                     Name  IsActive\n0            1  A Cappella/Vocal Groups      True\n1            2                 Acrobats      True\n2            3                  African      True\n3            4       Animal/Circus Acts      True\n4            5             Audio Visual      True\n\nThe head of artist_df is:\n   ArtistId                 Name  MailingCountryId PhysicalAddressCity  \\\n0         2                    O               1.0            RICHMOND   \n1         3        GROOVE DELUXE               1.0           ROCK HILL   \n2         4  QUINTON PARKER BAND               1.0             ASHLAND   \n3         5  BILL BOLEN BAND (4)               1.0         CHAPEL HILL   \n4         6       88 KEYS WILSON               1.0     CHARLOTTESVILLE   \n\n   PhysicalAddressStateId  PhysicalGeoLatitude  PhysicalGeoLongitude  \\\n0                    46.0              37.5770              -77.5388   \n1                    41.0              34.8867              -81.0208   \n2                    46.0              37.7596              -77.4822   \n3                    28.0              35.9672              -79.0444   \n4                    46.0              38.0884              -78.5562   \n\n   IsActive  IsExclusive             CreatedDate             UpdatedDate  \\\n0      True        False 2018-06-02 04:05:01.677 2018-06-02 17:21:47.147   \n1      True        False 2018-06-02 04:05:01.677 2018-06-02 17:21:47.147   \n2      True        False 2018-06-02 04:05:01.677 2018-06-02 17:21:47.147   \n3      True        False 2018-06-02 04:05:01.683 2018-09-19 15:21:38.730   \n4      True        False 2018-06-02 04:05:01.683 2019-11-18 15:16:17.807   \n\n   IsNational  IsNotParticipating  \n0       False               False  \n1       False               False  \n2       False               False  \n3       False               False  \n4       False               False  \n\nThe head of df_venue is:\n   VenueId  AgentId                               Name  VenueSettingId  \\\n0        1    141.0                     HILTON ATLANTA               3   \n1        2    141.0           MARRIOTT MARQUIS ATLANTA               3   \n2        3    430.0  Moreland Landing @ Palmetto Bluff               2   \n3        4    141.0        EVERGREEN CONFERENCE CENTER               3   \n4        5    141.0              MERCEDES-BENZ STADIUM               1   \n\n   IsSettingCovered                          MailingAddress1  \\\n0             False                  255 COURTLAND STREET NE   \n1             False              265 PEACHTREE CENTER AVENUE   \n2              True                            Moreland Road   \n3             False              EVERGREEN CONFERENCE CENTER   \n4             False  1414 ANDREW YOUNG INTERNATIONAL BLVD NW   \n\n    MailingAddress2     MailingCity  MailingStateId MailingZip  ...  \\\n0                           ATLANTA              11      30303  ...   \n1                           ATLANTA              11      30303  ...   \n2                          BLUFFTON              41      29910  ...   \n3  1 LAKEVIEW DRIVE  STONE MOUNTAIN              11      30086  ...   \n4                           ATLANTA              11      30313  ...   \n\n              PhysicalAddress2    PhysicalCity PhysicalStateId PhysicalZip  \\\n0                                      ATLANTA              11       30303   \n1  265 PEACHTREE CENTER AVENUE         ATLANTA              11       30303   \n2                                     BLUFFTON              41       29910   \n3             1 LAKEVIEW DRIVE  STONE MOUNTAIN              11       30086   \n4                                      ATLANTA              11       30313   \n\n   PhysicalCountryId                                              Notes  \\\n0                  1                                                      \n1                  1                                                      \n2                  1  all the way at the end of Moreland Road, can't...   \n3                  1                                                      \n4                  1                                                      \n\n   IsActive PresenterId             CreatedDate  CreatedById  \n0      True  10000011.0 2018-06-04 11:42:41.587          141  \n1      True   5787203.0 2018-06-04 11:46:28.407          141  \n2      True   8571076.0 2018-06-04 11:52:10.490          445  \n3      True   6061900.0 2018-06-04 11:55:11.247          141  \n4      True     32803.0 2018-06-04 11:56:29.607          141  \n\n[5 rows x 22 columns]\n\nThe head of df_bluecardartist is:\n   BlueCardArtistId  BlueCardId  ArtistId   Gross  Net      Notes  IsDeleted  \\\n0                 1           0       136  3250.0  0.0    Unknown      False   \n1                 2           0       296  7750.0  0.0  w/ female      False   \n2                 3           0     11183     0.0  0.0    Unknown      False   \n3                 4           0     15104     0.0  0.0    Unknown      False   \n4                 5           0     15104     0.0  0.0    Unknown      False   \n\n              CreatedDate  CreatedById  \n0 2018-06-02 04:06:42.950            0  \n1 2018-06-02 04:06:42.950            0  \n2 2018-06-02 04:06:42.950            0  \n3 2018-06-02 04:06:42.950            0  \n4 2018-06-02 04:06:42.950            0  \n\nThe head of df_feedback is:\n   ArtistFeedbackId  ArtistId  PresenterPortalId  ContractId  IsNegative  \\\n0                 1      3061                  1      100304       False   \n1                 2       918                  2      103526       False   \n2                 3       154                  3      104617       False   \n3                 4        55                  4      105392       False   \n4                 5        32                  5      105486       False   \n\n  ReviewDate                                           Feedback  \\\n0 2001-07-19  THE BREEZE BAND ARE THE BEST. THEY ARE NOT ONL...   \n1 1991-01-21                               EVRYTHING WENT GREAT   \n2 1991-02-15                                      BKD MIRAGE 91   \n3 1991-01-09                                    BKD MAINSTAY 91   \n4 1991-01-09                       BAND PLAYS REGULARLY AT CLUB   \n\n          CreatedDate  CreatedById  \n0 2006-06-07 09:03:58            0  \n1 2006-06-07 05:42:43            0  \n2 2006-06-07 02:25:48            0  \n3 2006-06-07 00:39:30            0  \n4 2006-06-07 00:19:13            0  \n\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1740700677611
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative filtering"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tables_svd = {\n",
        "    \"df_presenter\": df_presenter,\n",
        "    \"artist_df\": artist_df,\n",
        "    \"df_feedback\": df_feedback,\n",
        "    \"df_genre\": df_genre,\n",
        "    \"df_act\": df_act\n",
        "}\n",
        "\n",
        "# Show the head of each dataframe\n",
        "for name, df in tables_svd.items():\n",
        "    print(f\"Head of {name}:\")\n",
        "    display(df.head())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Head of df_presenter:\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   PresenterId  AgentId                  AccountName OrganizationName  \\\n0            0      281                          ASD          Unknown   \n1            8      107  COLLEGE OF WILLIAM AND MARY    BETA THETA PI   \n2           32      443               WAKE SUPPLY CO          Unknown   \n3           82      435            MARRIOTT/RICHMOND          Unknown   \n4           85      253                    [Unknown]          Unknown   \n\n   PresenterTypeId                               MailingAddress1  \\\n0               99                                       Unknown   \n1               49                          700 UKROP WAY UNIT M   \n2                8  1700 JEFFREY ST                                \n3               99                                       Unknown   \n4               99                                       Unknown   \n\n             MailingAddress2   MailingCity  MailingStateId MailingZip  ...  \\\n0                    Unknown       Unknown             999    Unknown  ...   \n1  COLLEGE OF WILLIAM & MARY  WILLIAMSBURG              46    Unknown  ...   \n2                    Unknown       RALEIGH              28      27610  ...   \n3                    Unknown       Unknown             999    Unknown  ...   \n4                    Unknown       Unknown             999    Unknown  ...   \n\n   PhysicalCity PhysicalStateId PhysicalZip PhysicalCountryId  \\\n0       Unknown             999     Unknown                 1   \n1  WILLIAMSBURG              46     Unknown                 1   \n2       RALEIGH              28       27610                 1   \n3       Unknown             999     Unknown                 1   \n4       Unknown             999     Unknown                 1   \n\n   PhysicalGeoLatitude PhysicalGeoLongitude  IsActive  CreatedDate  \\\n0              35.7373           -80.770107     False   2016-11-10   \n1              37.2458           -76.697000      True   2012-06-04   \n2              35.7455           -78.546700     False   2003-12-30   \n3              35.7373           -80.770107     False   2012-04-11   \n4              35.7373           -80.770107     False   2009-06-12   \n\n   CreatedById  ParentPresenterId  \n0          281                  0  \n1          107                  0  \n2          443                  0  \n3          435                  0  \n4          253                  0  \n\n[5 rows x 23 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PresenterId</th>\n      <th>AgentId</th>\n      <th>AccountName</th>\n      <th>OrganizationName</th>\n      <th>PresenterTypeId</th>\n      <th>MailingAddress1</th>\n      <th>MailingAddress2</th>\n      <th>MailingCity</th>\n      <th>MailingStateId</th>\n      <th>MailingZip</th>\n      <th>...</th>\n      <th>PhysicalCity</th>\n      <th>PhysicalStateId</th>\n      <th>PhysicalZip</th>\n      <th>PhysicalCountryId</th>\n      <th>PhysicalGeoLatitude</th>\n      <th>PhysicalGeoLongitude</th>\n      <th>IsActive</th>\n      <th>CreatedDate</th>\n      <th>CreatedById</th>\n      <th>ParentPresenterId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>281</td>\n      <td>ASD</td>\n      <td>Unknown</td>\n      <td>99</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>999</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>999</td>\n      <td>Unknown</td>\n      <td>1</td>\n      <td>35.7373</td>\n      <td>-80.770107</td>\n      <td>False</td>\n      <td>2016-11-10</td>\n      <td>281</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>107</td>\n      <td>COLLEGE OF WILLIAM AND MARY</td>\n      <td>BETA THETA PI</td>\n      <td>49</td>\n      <td>700 UKROP WAY UNIT M</td>\n      <td>COLLEGE OF WILLIAM &amp; MARY</td>\n      <td>WILLIAMSBURG</td>\n      <td>46</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>WILLIAMSBURG</td>\n      <td>46</td>\n      <td>Unknown</td>\n      <td>1</td>\n      <td>37.2458</td>\n      <td>-76.697000</td>\n      <td>True</td>\n      <td>2012-06-04</td>\n      <td>107</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>443</td>\n      <td>WAKE SUPPLY CO</td>\n      <td>Unknown</td>\n      <td>8</td>\n      <td>1700 JEFFREY ST</td>\n      <td>Unknown</td>\n      <td>RALEIGH</td>\n      <td>28</td>\n      <td>27610</td>\n      <td>...</td>\n      <td>RALEIGH</td>\n      <td>28</td>\n      <td>27610</td>\n      <td>1</td>\n      <td>35.7455</td>\n      <td>-78.546700</td>\n      <td>False</td>\n      <td>2003-12-30</td>\n      <td>443</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>82</td>\n      <td>435</td>\n      <td>MARRIOTT/RICHMOND</td>\n      <td>Unknown</td>\n      <td>99</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>999</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>999</td>\n      <td>Unknown</td>\n      <td>1</td>\n      <td>35.7373</td>\n      <td>-80.770107</td>\n      <td>False</td>\n      <td>2012-04-11</td>\n      <td>435</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>85</td>\n      <td>253</td>\n      <td>[Unknown]</td>\n      <td>Unknown</td>\n      <td>99</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>999</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>999</td>\n      <td>Unknown</td>\n      <td>1</td>\n      <td>35.7373</td>\n      <td>-80.770107</td>\n      <td>False</td>\n      <td>2009-06-12</td>\n      <td>253</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Head of artist_df:\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   ArtistId                 Name  MailingCountryId PhysicalAddressCity  \\\n0         2                    O               1.0            RICHMOND   \n1         3        GROOVE DELUXE               1.0           ROCK HILL   \n2         4  QUINTON PARKER BAND               1.0             ASHLAND   \n3         5  BILL BOLEN BAND (4)               1.0         CHAPEL HILL   \n4         6       88 KEYS WILSON               1.0     CHARLOTTESVILLE   \n\n   PhysicalAddressStateId  PhysicalGeoLatitude  PhysicalGeoLongitude  \\\n0                    46.0              37.5770              -77.5388   \n1                    41.0              34.8867              -81.0208   \n2                    46.0              37.7596              -77.4822   \n3                    28.0              35.9672              -79.0444   \n4                    46.0              38.0884              -78.5562   \n\n   IsActive  IsExclusive             CreatedDate             UpdatedDate  \\\n0      True        False 2018-06-02 04:05:01.677 2018-06-02 17:21:47.147   \n1      True        False 2018-06-02 04:05:01.677 2018-06-02 17:21:47.147   \n2      True        False 2018-06-02 04:05:01.677 2018-06-02 17:21:47.147   \n3      True        False 2018-06-02 04:05:01.683 2018-09-19 15:21:38.730   \n4      True        False 2018-06-02 04:05:01.683 2019-11-18 15:16:17.807   \n\n   IsNational  IsNotParticipating  \n0       False               False  \n1       False               False  \n2       False               False  \n3       False               False  \n4       False               False  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArtistId</th>\n      <th>Name</th>\n      <th>MailingCountryId</th>\n      <th>PhysicalAddressCity</th>\n      <th>PhysicalAddressStateId</th>\n      <th>PhysicalGeoLatitude</th>\n      <th>PhysicalGeoLongitude</th>\n      <th>IsActive</th>\n      <th>IsExclusive</th>\n      <th>CreatedDate</th>\n      <th>UpdatedDate</th>\n      <th>IsNational</th>\n      <th>IsNotParticipating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>O</td>\n      <td>1.0</td>\n      <td>RICHMOND</td>\n      <td>46.0</td>\n      <td>37.5770</td>\n      <td>-77.5388</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2018-06-02 04:05:01.677</td>\n      <td>2018-06-02 17:21:47.147</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>GROOVE DELUXE</td>\n      <td>1.0</td>\n      <td>ROCK HILL</td>\n      <td>41.0</td>\n      <td>34.8867</td>\n      <td>-81.0208</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2018-06-02 04:05:01.677</td>\n      <td>2018-06-02 17:21:47.147</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>QUINTON PARKER BAND</td>\n      <td>1.0</td>\n      <td>ASHLAND</td>\n      <td>46.0</td>\n      <td>37.7596</td>\n      <td>-77.4822</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2018-06-02 04:05:01.677</td>\n      <td>2018-06-02 17:21:47.147</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>BILL BOLEN BAND (4)</td>\n      <td>1.0</td>\n      <td>CHAPEL HILL</td>\n      <td>28.0</td>\n      <td>35.9672</td>\n      <td>-79.0444</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2018-06-02 04:05:01.683</td>\n      <td>2018-09-19 15:21:38.730</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>88 KEYS WILSON</td>\n      <td>1.0</td>\n      <td>CHARLOTTESVILLE</td>\n      <td>46.0</td>\n      <td>38.0884</td>\n      <td>-78.5562</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2018-06-02 04:05:01.683</td>\n      <td>2019-11-18 15:16:17.807</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Head of df_feedback:\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   ArtistFeedbackId  ArtistId  PresenterPortalId  ContractId  IsNegative  \\\n0                 1      3061                  1      100304       False   \n1                 2       918                  2      103526       False   \n2                 3       154                  3      104617       False   \n3                 4        55                  4      105392       False   \n4                 5        32                  5      105486       False   \n\n  ReviewDate                                           Feedback  \\\n0 2001-07-19  THE BREEZE BAND ARE THE BEST. THEY ARE NOT ONL...   \n1 1991-01-21                               EVRYTHING WENT GREAT   \n2 1991-02-15                                      BKD MIRAGE 91   \n3 1991-01-09                                    BKD MAINSTAY 91   \n4 1991-01-09                       BAND PLAYS REGULARLY AT CLUB   \n\n          CreatedDate  CreatedById  \n0 2006-06-07 09:03:58            0  \n1 2006-06-07 05:42:43            0  \n2 2006-06-07 02:25:48            0  \n3 2006-06-07 00:39:30            0  \n4 2006-06-07 00:19:13            0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArtistFeedbackId</th>\n      <th>ArtistId</th>\n      <th>PresenterPortalId</th>\n      <th>ContractId</th>\n      <th>IsNegative</th>\n      <th>ReviewDate</th>\n      <th>Feedback</th>\n      <th>CreatedDate</th>\n      <th>CreatedById</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3061</td>\n      <td>1</td>\n      <td>100304</td>\n      <td>False</td>\n      <td>2001-07-19</td>\n      <td>THE BREEZE BAND ARE THE BEST. THEY ARE NOT ONL...</td>\n      <td>2006-06-07 09:03:58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>918</td>\n      <td>2</td>\n      <td>103526</td>\n      <td>False</td>\n      <td>1991-01-21</td>\n      <td>EVRYTHING WENT GREAT</td>\n      <td>2006-06-07 05:42:43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>154</td>\n      <td>3</td>\n      <td>104617</td>\n      <td>False</td>\n      <td>1991-02-15</td>\n      <td>BKD MIRAGE 91</td>\n      <td>2006-06-07 02:25:48</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>55</td>\n      <td>4</td>\n      <td>105392</td>\n      <td>False</td>\n      <td>1991-01-09</td>\n      <td>BKD MAINSTAY 91</td>\n      <td>2006-06-07 00:39:30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>32</td>\n      <td>5</td>\n      <td>105486</td>\n      <td>False</td>\n      <td>1991-01-09</td>\n      <td>BAND PLAYS REGULARLY AT CLUB</td>\n      <td>2006-06-07 00:19:13</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Head of df_genre:\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   GenreTypeId                     Name  IsActive\n0            1  A Cappella/Vocal Groups      True\n1            2                 Acrobats      True\n2            3                  African      True\n3            4       Animal/Circus Acts      True\n4            5             Audio Visual      True",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GenreTypeId</th>\n      <th>Name</th>\n      <th>IsActive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A Cappella/Vocal Groups</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Acrobats</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>African</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Animal/Circus Acts</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Audio Visual</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Head of df_act:\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   ActTypeId           Name  IsActive\n0          1          Bands      True\n1          2      Classical      True\n2          3      Comedians      True\n3          4            DJs      True\n4          5  International      True",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ActTypeId</th>\n      <th>Name</th>\n      <th>IsActive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Bands</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Classical</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Comedians</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>DJs</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>International</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1740700677853
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the column names and data types\n",
        "print(df_feedback.info())\n",
        "\n",
        "# Check unique values in key columns to understand data distribution\n",
        "print(\"Unique values in IsNegative column:\", df_feedback[\"IsNegative\"].unique())\n",
        "\n",
        "# Check the number of unique presenters and artists in feedback\n",
        "print(\"Unique Presenters in Feedback:\", df_feedback[\"PresenterPortalId\"].nunique())\n",
        "print(\"Unique Artists in Feedback:\", df_feedback[\"ArtistId\"].nunique())\n",
        "\n",
        "# Check if we have meaningful text feedback\n",
        "print(df_feedback[\"Feedback\"].head(10))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 47430 entries, 0 to 47429\nData columns (total 9 columns):\n #   Column             Non-Null Count  Dtype         \n---  ------             --------------  -----         \n 0   ArtistFeedbackId   47430 non-null  int64         \n 1   ArtistId           47430 non-null  int64         \n 2   PresenterPortalId  47430 non-null  int64         \n 3   ContractId         47430 non-null  int64         \n 4   IsNegative         47430 non-null  bool          \n 5   ReviewDate         47430 non-null  datetime64[ns]\n 6   Feedback           47430 non-null  object        \n 7   CreatedDate        47430 non-null  datetime64[ns]\n 8   CreatedById        47430 non-null  int64         \ndtypes: bool(1), datetime64[ns](2), int64(5), object(1)\nmemory usage: 2.9+ MB\nNone\nUnique values in IsNegative column: [False  True]\nUnique Presenters in Feedback: 47216\nUnique Artists in Feedback: 4267\n0    THE BREEZE BAND ARE THE BEST. THEY ARE NOT ONL...\n1                                 EVRYTHING WENT GREAT\n2                                        BKD MIRAGE 91\n3                                      BKD MAINSTAY 91\n4                         BAND PLAYS REGULARLY AT CLUB\n5                                             REBKD 91\n6    BAND WAS GOOD-DO NOT USE A REF. PRES. IS A JER...\n7                            BOOKED RHYTMATIX 12.31.91\n8        UNDECIDED ABOUT DANCE 12/31/91 SMALL CROWD 90\n9                                         REBKD FOR 91\nName: Feedback, dtype: object\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1740700677914
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Numerical Ratings Column\n",
        "# Convert IsNegative into a numerical rating\n",
        "df_feedback[\"Rating\"] = df_feedback[\"IsNegative\"].apply(lambda x: 0 if x else 1)\n",
        "\n",
        "# Display updated feedback data\n",
        "print(df_feedback[[\"PresenterPortalId\", \"ArtistId\", \"Rating\"]].head(10))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   PresenterPortalId  ArtistId  Rating\n0                  1      3061       1\n1                  2       918       1\n2                  3       154       1\n3                  4        55       1\n4                  5        32       1\n5                  6       297       1\n6                  7       203       1\n7                  8        84       1\n8                  9      2254       1\n9                 10      2181       1\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1740700677963
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing the User-Item Interaction Matrix"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_item_matrix = df_feedback.pivot_table(index='PresenterPortalId', \n",
        "                                           columns='ArtistId', \n",
        "                                           values='Rating', \n",
        "                                           fill_value=0)  # Fill missing values with 0 (No interaction)\n",
        "\n",
        "# Display the matrix\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show dataframe\n",
        "user_item_matrix.head()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "ArtistId           2       3       5       6       7       8       16      \\\nPresenterPortalId                                                           \n0                       0       0       0       0       0       0       0   \n1                       0       0       0       0       0       0       0   \n2                       0       0       0       0       0       0       0   \n3                       0       0       0       0       0       0       0   \n4                       0       0       0       0       0       0       0   \n\nArtistId           17      21      23      ...  102354  102531  102534  \\\nPresenterPortalId                          ...                           \n0                       0       0       0  ...       1       0       0   \n1                       0       0       0  ...       0       0       0   \n2                       0       0       0  ...       0       0       0   \n3                       0       0       0  ...       0       0       0   \n4                       0       0       0  ...       0       0       0   \n\nArtistId           102691  103147  103155  103202  103213  103352  103546  \nPresenterPortalId                                                          \n0                       0       0       0       0       1       0       0  \n1                       0       0       0       0       0       0       0  \n2                       0       0       0       0       0       0       0  \n3                       0       0       0       0       0       0       0  \n4                       0       0       0       0       0       0       0  \n\n[5 rows x 4267 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>ArtistId</th>\n      <th>2</th>\n      <th>3</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>16</th>\n      <th>17</th>\n      <th>21</th>\n      <th>23</th>\n      <th>...</th>\n      <th>102354</th>\n      <th>102531</th>\n      <th>102534</th>\n      <th>102691</th>\n      <th>103147</th>\n      <th>103155</th>\n      <th>103202</th>\n      <th>103213</th>\n      <th>103352</th>\n      <th>103546</th>\n    </tr>\n    <tr>\n      <th>PresenterPortalId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 4267 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1740700693638
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVD (Singular Value Decomposition) for Collaborative Filtering!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Define the number of latent features\n",
        "n_components = 80  # You can tune this parameter\n",
        "\n",
        "# Apply Truncated SVD\n",
        "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "user_factors = svd.fit_transform(user_item_matrix)\n",
        "artist_factors = svd.components_\n",
        "\n",
        "# Display results\n",
        "print(f\"Shape of User Factors (U matrix): {user_factors.shape}\")\n",
        "print(f\"Shape of Artist Factors (V matrix): {artist_factors.shape}\")\n",
        "print(f\"Explained Variance Ratio: {np.sum(svd.explained_variance_ratio_):.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Shape of User Factors (U matrix): (47216, 80)\nShape of Artist Factors (V matrix): (80, 4267)\nExplained Variance Ratio: 0.4500\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1740700704203
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Explained Variance Ratio = 45%, meaning SVD captures about 45% of the variation in user preferences. We might need to increase n_components later for better results"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Predicted Ratings"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct the matrix\n",
        "predicted_ratings = np.dot(user_factors, artist_factors)\n",
        "\n",
        "# Convert to DataFrame for readability\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, \n",
        "                                    index=user_item_matrix.index, \n",
        "                                    columns=user_item_matrix.columns)\n",
        "\n",
        "# Display first few rows\n",
        "predicted_ratings_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "ArtistId                 2             3             5             6       \\\nPresenterPortalId                                                           \n0                 -2.387177e-09  7.708342e-05 -4.627905e-09 -1.134064e-09   \n1                 -1.515541e-20 -1.629205e-16  2.220070e-21  3.184640e-21   \n2                  4.275571e-11 -1.224628e-06 -2.317748e-10  5.177337e-12   \n3                 -5.553936e-12  1.794785e-08  9.033720e-12 -2.092563e-13   \n4                 -8.381606e-13 -2.204878e-09  8.204516e-13  8.944628e-14   \n\nArtistId                 7             8             16            17      \\\nPresenterPortalId                                                           \n0                 -3.003064e-08 -6.648920e-10 -1.473540e-13 -1.078488e-02   \n1                  4.615757e-21  1.487343e-20 -3.851917e-26 -1.555525e-14   \n2                 -2.263593e-10 -4.826327e-11  6.481200e-16  3.648890e-06   \n3                 -3.099087e-11 -1.523227e-12  8.304679e-17 -2.777000e-06   \n4                 -1.627413e-12  2.759124e-13 -2.364733e-17 -3.381680e-07   \n\nArtistId                 21            23      ...        102354  \\\nPresenterPortalId                              ...                 \n0                 -1.573149e-09  1.589497e-07  ...  5.317093e-02   \n1                  2.857783e-21 -3.183959e-17  ... -3.868752e-15   \n2                 -2.771406e-11  3.483004e-08  ... -2.562504e-05   \n3                 -4.303667e-13  4.359223e-09  ...  1.198464e-07   \n4                  2.429525e-14 -4.994465e-11  ... -1.769129e-07   \n\nArtistId                 102531        102534        102691        103147  \\\nPresenterPortalId                                                           \n0                 -2.500958e-10 -3.240663e-12  2.142454e-11 -6.788776e-10   \n1                 -6.802033e-22 -3.967284e-23 -2.832694e-22  1.104935e-21   \n2                  4.748849e-12  1.643866e-13 -3.980932e-13  7.401675e-12   \n3                  1.448915e-13  4.815079e-15  1.733957e-13  2.623515e-14   \n4                 -4.477055e-14 -1.357506e-15 -7.655815e-15  5.362027e-15   \n\nArtistId                 103155        103202        103213        103352  \\\nPresenterPortalId                                                           \n0                 -4.535471e-10  3.301357e-13  5.317093e-02  6.927187e-14   \n1                  6.854848e-22 -4.469924e-25 -3.868752e-15 -2.281613e-25   \n2                  1.219241e-12 -4.284984e-15 -2.562504e-05 -3.627420e-15   \n3                  7.264804e-14  1.010147e-16  1.198464e-07  3.434050e-17   \n4                  7.368419e-15  1.092469e-18 -1.769129e-07  9.460799e-18   \n\nArtistId                 103546  \nPresenterPortalId                \n0                 -3.152391e-13  \n1                  4.413733e-26  \n2                 -1.629740e-15  \n3                 -9.496436e-17  \n4                 -1.421081e-17  \n\n[5 rows x 4267 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>ArtistId</th>\n      <th>2</th>\n      <th>3</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>16</th>\n      <th>17</th>\n      <th>21</th>\n      <th>23</th>\n      <th>...</th>\n      <th>102354</th>\n      <th>102531</th>\n      <th>102534</th>\n      <th>102691</th>\n      <th>103147</th>\n      <th>103155</th>\n      <th>103202</th>\n      <th>103213</th>\n      <th>103352</th>\n      <th>103546</th>\n    </tr>\n    <tr>\n      <th>PresenterPortalId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-2.387177e-09</td>\n      <td>7.708342e-05</td>\n      <td>-4.627905e-09</td>\n      <td>-1.134064e-09</td>\n      <td>-3.003064e-08</td>\n      <td>-6.648920e-10</td>\n      <td>-1.473540e-13</td>\n      <td>-1.078488e-02</td>\n      <td>-1.573149e-09</td>\n      <td>1.589497e-07</td>\n      <td>...</td>\n      <td>5.317093e-02</td>\n      <td>-2.500958e-10</td>\n      <td>-3.240663e-12</td>\n      <td>2.142454e-11</td>\n      <td>-6.788776e-10</td>\n      <td>-4.535471e-10</td>\n      <td>3.301357e-13</td>\n      <td>5.317093e-02</td>\n      <td>6.927187e-14</td>\n      <td>-3.152391e-13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.515541e-20</td>\n      <td>-1.629205e-16</td>\n      <td>2.220070e-21</td>\n      <td>3.184640e-21</td>\n      <td>4.615757e-21</td>\n      <td>1.487343e-20</td>\n      <td>-3.851917e-26</td>\n      <td>-1.555525e-14</td>\n      <td>2.857783e-21</td>\n      <td>-3.183959e-17</td>\n      <td>...</td>\n      <td>-3.868752e-15</td>\n      <td>-6.802033e-22</td>\n      <td>-3.967284e-23</td>\n      <td>-2.832694e-22</td>\n      <td>1.104935e-21</td>\n      <td>6.854848e-22</td>\n      <td>-4.469924e-25</td>\n      <td>-3.868752e-15</td>\n      <td>-2.281613e-25</td>\n      <td>4.413733e-26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.275571e-11</td>\n      <td>-1.224628e-06</td>\n      <td>-2.317748e-10</td>\n      <td>5.177337e-12</td>\n      <td>-2.263593e-10</td>\n      <td>-4.826327e-11</td>\n      <td>6.481200e-16</td>\n      <td>3.648890e-06</td>\n      <td>-2.771406e-11</td>\n      <td>3.483004e-08</td>\n      <td>...</td>\n      <td>-2.562504e-05</td>\n      <td>4.748849e-12</td>\n      <td>1.643866e-13</td>\n      <td>-3.980932e-13</td>\n      <td>7.401675e-12</td>\n      <td>1.219241e-12</td>\n      <td>-4.284984e-15</td>\n      <td>-2.562504e-05</td>\n      <td>-3.627420e-15</td>\n      <td>-1.629740e-15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-5.553936e-12</td>\n      <td>1.794785e-08</td>\n      <td>9.033720e-12</td>\n      <td>-2.092563e-13</td>\n      <td>-3.099087e-11</td>\n      <td>-1.523227e-12</td>\n      <td>8.304679e-17</td>\n      <td>-2.777000e-06</td>\n      <td>-4.303667e-13</td>\n      <td>4.359223e-09</td>\n      <td>...</td>\n      <td>1.198464e-07</td>\n      <td>1.448915e-13</td>\n      <td>4.815079e-15</td>\n      <td>1.733957e-13</td>\n      <td>2.623515e-14</td>\n      <td>7.264804e-14</td>\n      <td>1.010147e-16</td>\n      <td>1.198464e-07</td>\n      <td>3.434050e-17</td>\n      <td>-9.496436e-17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-8.381606e-13</td>\n      <td>-2.204878e-09</td>\n      <td>8.204516e-13</td>\n      <td>8.944628e-14</td>\n      <td>-1.627413e-12</td>\n      <td>2.759124e-13</td>\n      <td>-2.364733e-17</td>\n      <td>-3.381680e-07</td>\n      <td>2.429525e-14</td>\n      <td>-4.994465e-11</td>\n      <td>...</td>\n      <td>-1.769129e-07</td>\n      <td>-4.477055e-14</td>\n      <td>-1.357506e-15</td>\n      <td>-7.655815e-15</td>\n      <td>5.362027e-15</td>\n      <td>7.368419e-15</td>\n      <td>1.092469e-18</td>\n      <td>-1.769129e-07</td>\n      <td>9.460799e-18</td>\n      <td>-1.421081e-17</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 4267 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1740700704962
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Top-N Recommendations for a Given Presenter"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n_recommendations(presenter_id, n=5):\n",
        "    \"\"\"\n",
        "    Get top N recommended artists for a given presenter based on predicted ratings.\n",
        "    \n",
        "    :param presenter_id: ID of the presenter for whom recommendations are generated.\n",
        "    :param n: Number of recommendations to return.\n",
        "    :return: DataFrame of top recommended artists with predicted scores.\n",
        "    \"\"\"\n",
        "    if presenter_id not in predicted_ratings_df.index:\n",
        "        print(\"Presenter ID not found in data.\")\n",
        "        return None\n",
        "\n",
        "    # Get predicted ratings for this presenter\n",
        "    presenter_ratings = predicted_ratings_df.loc[presenter_id]\n",
        "\n",
        "    # Sort artists by predicted rating in descending order\n",
        "    top_artists = presenter_ratings.sort_values(ascending=False).head(n)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    recommendations = pd.DataFrame({\"ArtistId\": top_artists.index, \"PredictedRating\": top_artists.values})\n",
        "\n",
        "    return recommendations"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1740700705028
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 5 recommendations for PresenterPortalId = 10\n",
        "presenter_id = 10\n",
        "top_recommendations = get_top_n_recommendations(presenter_id, n=5)\n",
        "\n",
        "# Display results\n",
        "top_recommendations"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "   ArtistId  PredictedRating\n0        77         0.000025\n1      3003         0.000023\n2      1104         0.000014\n3      8701         0.000014\n4        37         0.000011",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArtistId</th>\n      <th>PredictedRating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>77</td>\n      <td>0.000025</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3003</td>\n      <td>0.000023</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1104</td>\n      <td>0.000014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8701</td>\n      <td>0.000014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>0.000011</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1740700705092
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predicted ratings are quite small, likely due to sparse feedback data.\n",
        "We can further filter or enhance recommendations using genre, location, or feedback scores."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving the performance\n",
        "### Normalize Predicted Ratings"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalize predicted ratings to a 0-1 scale\n",
        "scaler = MinMaxScaler()\n",
        "normalized_ratings = scaler.fit_transform(predicted_ratings)\n",
        "\n",
        "# Convert back to a DataFrame\n",
        "normalized_ratings_df = pd.DataFrame(normalized_ratings, \n",
        "                                     index=predicted_ratings_df.index, \n",
        "                                     columns=predicted_ratings_df.columns)\n",
        "\n",
        "# Display the first few rows\n",
        "print(normalized_ratings_df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ArtistId             2         3         5         6         7         8       \\\nPresenterPortalId                                                               \n0                  0.464120  1.000000  0.343387  0.191725  0.194859  0.370378   \n1                  0.527295  0.516971  0.446763  0.461578  0.505693  0.413311   \n2                  0.528426  0.509297  0.441585  0.462810  0.503350  0.410194   \n3                  0.527148  0.517084  0.446964  0.461529  0.505373  0.413212   \n4                  0.527272  0.516957  0.446781  0.461600  0.505676  0.413328   \n\nArtistId             16        17        21        23      ...    102354  \\\nPresenterPortalId                                          ...             \n0                  0.263163  0.287736  0.030252  0.000017  ...  1.000000   \n1                  0.468206  0.551469  0.342953  0.000017  ...  0.070793   \n2                  0.469108  0.551558  0.337444  0.000017  ...  0.070345   \n3                  0.468322  0.551401  0.342868  0.000017  ...  0.070795   \n4                  0.468173  0.551461  0.342958  0.000017  ...  0.070790   \n\nArtistId             102531    102534    102691    103147    103155    103202  \\\nPresenterPortalId                                                               \n0                  0.172865  0.525423  0.505252  0.000000  0.000000  1.000000   \n1                  0.405836  0.594493  0.477609  0.521406  0.502458  0.540921   \n2                  0.410259  0.597997  0.477096  0.527091  0.503809  0.534963   \n3                  0.405971  0.594596  0.477833  0.521426  0.502538  0.541062   \n4                  0.405794  0.594465  0.477599  0.521410  0.502466  0.540923   \n\nArtistId             103213    103352    103546  \nPresenterPortalId                                \n0                  1.000000  0.648420  0.081701  \n1                  0.070793  0.536650  0.529455  \n2                  0.070345  0.530798  0.527141  \n3                  0.070795  0.536706  0.529320  \n4                  0.070790  0.536666  0.529435  \n\n[5 rows x 4267 columns]\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1740700706958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve Adjusted Top-N Recommendations\n",
        "def get_adjusted_top_n_recommendations(presenter_id, n=5):\n",
        "    \"\"\"\n",
        "    Get top N recommended artists for a given presenter using normalized ratings.\n",
        "    \n",
        "    :param presenter_id: ID of the presenter for whom recommendations are generated.\n",
        "    :param n: Number of recommendations to return.\n",
        "    :return: DataFrame of top recommended artists with predicted scores.\n",
        "    \"\"\"\n",
        "    if presenter_id not in normalized_ratings_df.index:\n",
        "        print(\"Presenter ID not found in data.\")\n",
        "        return None\n",
        "\n",
        "    # Get normalized predicted ratings for this presenter\n",
        "    presenter_ratings = normalized_ratings_df.loc[presenter_id]\n",
        "\n",
        "    # Sort artists by predicted rating in descending order\n",
        "    top_artists = presenter_ratings.sort_values(ascending=False).head(n)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    recommendations = pd.DataFrame({\"ArtistId\": top_artists.index, \"NormalizedRating\": top_artists.values})\n",
        "\n",
        "    return recommendations"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1740700707028
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 5 recommendations for PresenterPortalId = 10\n",
        "presenter_id = 10\n",
        "adjusted_top_recommendations = get_adjusted_top_n_recommendations(presenter_id, n=5)\n",
        "\n",
        "# Display results\n",
        "print(adjusted_top_recommendations)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   ArtistId  NormalizedRating\n0      5349          0.835598\n1     14809          0.806696\n2      2378          0.804622\n3      6984          0.799171\n4      1328          0.787272\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1740700707087
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge Recommendations with Artist Names\n",
        "adjusted_top_recommendations = adjusted_top_recommendations.merge(artist_df[[\"ArtistId\", \"Name\"]], on=\"ArtistId\", how=\"left\")\n",
        "\n",
        "# Rename column for clarity\n",
        "adjusted_top_recommendations.rename(columns={\"Name\": \"ArtistName\"}, inplace=True)\n",
        "\n",
        "# Display updated recommendations\n",
        "adjusted_top_recommendations\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "   ArtistId  NormalizedRating              ArtistName\n0      5349          0.835598             GATOR GUMBO\n1     14809          0.806696    BOOK IT INCORPORATED\n2      2378          0.804622  PIANIST - PAUL BARTSCH\n3      6984          0.799171                JAY MOHR\n4      1328          0.787272                   MISTA",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArtistId</th>\n      <th>NormalizedRating</th>\n      <th>ArtistName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5349</td>\n      <td>0.835598</td>\n      <td>GATOR GUMBO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14809</td>\n      <td>0.806696</td>\n      <td>BOOK IT INCORPORATED</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2378</td>\n      <td>0.804622</td>\n      <td>PIANIST - PAUL BARTSCH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6984</td>\n      <td>0.799171</td>\n      <td>JAY MOHR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1328</td>\n      <td>0.787272</td>\n      <td>MISTA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1740700707145
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Improving Model Performance (Hyperparameter Tuning & Enhancements)\n",
        "### Tune n_components for SVD"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "\n",
        "# Test different n_components\n",
        "best_explained_variance = 0\n",
        "best_n = 0\n",
        "explained_variances = {}\n",
        "\n",
        "for n in [100, 120, 150, 180, 200]:  # Different values to test\n",
        "    svd = TruncatedSVD(n_components=n, random_state=42)\n",
        "    user_factors = svd.fit_transform(user_item_matrix)\n",
        "    artist_factors = svd.components_\n",
        "    \n",
        "    explained_variance = np.sum(svd.explained_variance_ratio_)\n",
        "    explained_variances[n] = explained_variance\n",
        "    \n",
        "    print(f\"n_components={n}, Explained Variance={explained_variance:.2%}\")\n",
        "    \n",
        "    if explained_variance > best_explained_variance:\n",
        "        best_explained_variance = explained_variance\n",
        "        best_n = n\n",
        "\n",
        "print(f\"\\nBest n_components={best_n} with Explained Variance={best_explained_variance:.2%}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "n_components=100, Explained Variance=48.61%\nn_components=120, Explained Variance=51.64%\nn_components=150, Explained Variance=55.40%\nn_components=180, Explained Variance=58.48%\nn_components=200, Explained Variance=60.25%\n\nBest n_components=200 with Explained Variance=60.25%\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1740700764847
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sparsity\n",
        "num_interactions = np.count_nonzero(user_item_matrix)\n",
        "total_possible_interactions = user_item_matrix.shape[0] * user_item_matrix.shape[1]\n",
        "sparsity = 1 - (num_interactions / total_possible_interactions)\n",
        "\n",
        "print(f\" Data Sparsity: {sparsity:.4%} of the matrix is empty (no interaction).\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " Data Sparsity: 99.9774% of the matrix is empty (no interaction).\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1740700857196
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the number of interactions per presenter and artist\n",
        "presenter_interactions = user_item_matrix.astype(bool).sum(axis=1)\n",
        "artist_interactions = user_item_matrix.astype(bool).sum(axis=0)\n",
        "\n",
        "# Set threshold for minimum interactions\n",
        "min_interactions = 3  \n",
        "\n",
        "# Filter presenters and artists with sufficient interactions\n",
        "active_presenters = presenter_interactions[presenter_interactions >= min_interactions].index\n",
        "active_artists = artist_interactions[artist_interactions >= min_interactions].index\n",
        "\n",
        "# Filter the user-item matrix\n",
        "filtered_user_item_matrix = user_item_matrix.loc[active_presenters, active_artists]\n",
        "\n",
        "print(f\" New Matrix Shape: {filtered_user_item_matrix.shape} (After filtering)\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " New Matrix Shape: (2, 1751) (After filtering)\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1740700909793
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert explicit ratings into implicit interactions\n",
        "implicit_feedback_matrix = user_item_matrix.copy()\n",
        "\n",
        "# Assign weights based on interaction frequency\n",
        "implicit_feedback_matrix = np.log1p(implicit_feedback_matrix)  # Log scaling to prevent bias from large counts\n",
        "\n",
        "# Normalize between 0 and 1\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "implicit_feedback_matrix = pd.DataFrame(\n",
        "    scaler.fit_transform(implicit_feedback_matrix),\n",
        "    index=user_item_matrix.index,\n",
        "    columns=user_item_matrix.columns\n",
        ")\n",
        "\n",
        "print(f\" Implicit Feedback Matrix Shape: {implicit_feedback_matrix.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " Implicit Feedback Matrix Shape: (47216, 4267)\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1740700990467
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Set optimal n_components based on previous tuning\n",
        "optimal_n_components = 200  # We can tune this later if needed\n",
        "\n",
        "# Apply Truncated SVD\n",
        "svd = TruncatedSVD(n_components=optimal_n_components, random_state=42)\n",
        "user_factors = svd.fit_transform(implicit_feedback_matrix)\n",
        "artist_factors = svd.components_\n",
        "\n",
        "# Compute explained variance\n",
        "explained_variance = np.sum(svd.explained_variance_ratio_) * 100\n",
        "print(f\" New Explained Variance: {explained_variance:.2f}%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " New Explained Variance: 60.25%\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1740701035311
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explained_variances = {}\n",
        "for n in [250, 300, 350, 400]:  # Increasing components\n",
        "    svd = TruncatedSVD(n_components=n, random_state=42)\n",
        "    svd.fit(implicit_feedback_matrix)\n",
        "\n",
        "    explained_variance = np.sum(svd.explained_variance_ratio_) * 100\n",
        "    explained_variances[n] = explained_variance\n",
        "    print(f\" Testing n_components={n} | Explained Variance={explained_variance:.2f}%\")\n",
        "\n",
        "# Find the best value\n",
        "best_n = max(explained_variances, key=explained_variances.get)\n",
        "best_explained_variance = explained_variances[best_n]\n",
        "print(f\"\\n Best n_components={best_n} with Explained Variance={best_explained_variance:.2f}%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " Testing n_components=250 | Explained Variance=64.00%\n Testing n_components=300 | Explained Variance=67.17%\n Testing n_components=350 | Explained Variance=69.82%\n Testing n_components=400 | Explained Variance=72.12%\n\n Best n_components=400 with Explained Variance=72.12%\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1740701176514
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SVD with best n_components\n",
        "svd = TruncatedSVD(n_components=400, random_state=42)\n",
        "user_factors = svd.fit_transform(implicit_feedback_matrix)\n",
        "artist_factors = svd.components_\n",
        "\n",
        "# Reconstruct the matrix\n",
        "predicted_ratings = np.dot(user_factors, artist_factors)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, \n",
        "                                    index=implicit_feedback_matrix.index, \n",
        "                                    columns=implicit_feedback_matrix.columns)\n",
        "\n",
        "print(\" Model retrained with n_components=400. Predictions updated!\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " Model retrained with n_components=400. Predictions updated!\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1740701231312
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n_recommendations(presenter_id, n=5):\n",
        "    \"\"\"\n",
        "    Get top N recommended artists for a given presenter based on predicted ratings.\n",
        "    \n",
        "    :param presenter_id: ID of the presenter for whom recommendations are generated.\n",
        "    :param n: Number of recommendations to return.\n",
        "    :return: DataFrame of top recommended artists with predicted scores.\n",
        "    \"\"\"\n",
        "    if presenter_id not in predicted_ratings_df.index:\n",
        "        print(\"Presenter ID not found in data.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get top-N artists\n",
        "    top_artists = predicted_ratings_df.loc[presenter_id].nlargest(n).reset_index()\n",
        "    top_artists.columns = [\"ArtistId\", \"PredictedRating\"]\n",
        "    \n",
        "    return top_artists\n",
        "\n",
        "# Get top 5 recommendations for PresenterPortalId=10\n",
        "presenter_id = 10\n",
        "top_recommendations = get_top_n_recommendations(presenter_id, n=5)\n",
        "\n",
        "print(\" Top 5 Recommended Artists:\")\n",
        "print(top_recommendations)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " Top 5 Recommended Artists:\n   ArtistId  PredictedRating\n0      2181         0.193504\n1     30263         0.095348\n2      2049         0.077884\n3       113         0.074200\n4     11234         0.067995\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1740701234447
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Ensure matrices have the same shape\n",
        "actual_ratings = implicit_feedback_matrix.to_numpy()\n",
        "predicted_ratings = predicted_ratings_df.to_numpy()\n",
        "\n",
        "# Mask non-zero values (actual interactions only)\n",
        "mask = actual_ratings > 0  \n",
        "\n",
        "# Compute RMSE & MAE\n",
        "rmse = np.sqrt(mean_squared_error(actual_ratings[mask], predicted_ratings[mask]))\n",
        "mae = mean_absolute_error(actual_ratings[mask], predicted_ratings[mask])\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " RMSE: 0.5146\n MAE: 0.2777\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1740701318981
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_at_k(predictions_df, actual_interactions, k=5):\n",
        "    \"\"\"\n",
        "    Compute Precision@K for top-k recommendations.\n",
        "    \n",
        "    :param predictions_df: DataFrame of predicted ratings.\n",
        "    :param actual_interactions: Actual user-item interactions.\n",
        "    :param k: Number of top items to consider.\n",
        "    :return: Precision@K score.\n",
        "    \"\"\"\n",
        "    total_precision = 0\n",
        "    num_users = predictions_df.shape[0]\n",
        "\n",
        "    for user_idx in range(num_users):\n",
        "        # Get top-K predictions\n",
        "        top_k_predicted = predictions_df.iloc[user_idx].nlargest(k).index.tolist()\n",
        "\n",
        "        # Get actual positive interactions (convert Series to array)\n",
        "        actual_liked = set(np.where(actual_interactions.iloc[user_idx].values > 0)[0])\n",
        "\n",
        "        # Compute precision\n",
        "        if actual_liked:\n",
        "            precision = len(set(top_k_predicted) & actual_liked) / k\n",
        "            total_precision += precision\n",
        "    \n",
        "    return total_precision / num_users if num_users > 0 else 0\n",
        "\n",
        "# Compute Precision@5\n",
        "precision_5 = precision_at_k(predicted_ratings_df, implicit_feedback_matrix, k=5)\n",
        "print(f\"Precision@5: {precision_5:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Precision@5: 0.0001\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1740701421266
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision@5 is extremely low (0.0001), meaning that the modelâ€™s top recommendations do not match actual user preferences well.\n",
        "However, RMSE (0.5146) and MAE (0.2777) are reasonable, indicating the predicted ratings align well with the dataset's structure.\n",
        "\n",
        "Since the dataset has 99.97% sparsity, this is expected. We need better ranking for recommendations rather than just predicting ratings."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightFM"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_presenter.isnull().sum())\n",
        "print(artist_df.isnull().sum())\n",
        "print(df_feedback.isnull().sum())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PresenterId                 0\nAgentId                     0\nAccountName                 0\nOrganizationName        39190\nPresenterTypeId             0\nMailingAddress1          3352\nMailingAddress2         16547\nMailingCity              2062\nMailingStateId              0\nMailingZip               4520\nMailingCountryId            0\nPhysicalAddress1         3352\nPhysicalAddress2        16547\nPhysicalCity             2062\nPhysicalStateId             0\nPhysicalZip              4520\nPhysicalCountryId           0\nPhysicalGeoLatitude      3930\nPhysicalGeoLongitude     3930\nNotes                   54001\nIsActive                    0\nCreatedDate                 0\nCreatedById                 0\nUpdatedDate             45937\nUpdatedById             45937\nArchiveDate             66975\nParentPresenterId           0\ndtype: int64\nArtistId                          0\nName                              0\nMailingCountryId               2655\nPhysicalAddressCity            3577\nPhysicalAddressStateId         3530\nPhysicalGeoLatitude            3617\nPhysicalGeoLongitude           3617\nIsActive                          0\nIsExclusive                       0\nExclusiveStartDate            23397\nNationalNetPriceLowerBound    21583\nNationalNetPriceUpperBound    21584\nNationalOneOffPrice           21569\nCreatedDate                       0\nUpdatedDate                   10838\nIsNational                        0\nIsNotParticipating                0\ndtype: int64\nArtistFeedbackId         0\nArtistId                 0\nPresenterPortalId        0\nContractId               0\nIsNegative               0\nReviewDate               0\nFeedback                 0\nAgentId              47203\nResponse             44397\nResponseDate         47203\nCreatedDate              0\nCreatedById              0\nUpdatedDate          47229\nUpdatedById          47229\ndtype: int64\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1740963864277
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique Presenters:\", df_presenter[\"PresenterId\"].nunique())\n",
        "print(\"Unique Artists:\", artist_df[\"ArtistId\"].nunique())\n",
        "print(\"Unique Feedback Records:\", df_feedback[\"ArtistId\"].nunique())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Unique Presenters: 89911\nUnique Artists: 23590\nUnique Feedback Records: 4267\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1740969979732
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping irrelevant columns with too many missing values\n",
        "df_presenter_cleaned = df_presenter.drop(columns=[\"Notes\", \"UpdatedDate\", \"UpdatedById\", \"ArchiveDate\"])\n",
        "artist_df_cleaned = artist_df.drop(columns=[\"ExclusiveStartDate\", \"UpdatedDate\"])\n",
        "df_feedback_cleaned = df_feedback.drop(columns=[\"Response\", \"ResponseDate\", \"UpdatedDate\", \"UpdatedById\", \"AgentId\"])\n",
        "\n",
        "# Filling missing categorical values with \"Unknown\"\n",
        "categorical_cols = [\"OrganizationName\", \"MailingAddress1\", \"MailingCity\", \"PhysicalAddress1\", \"PhysicalCity\"]\n",
        "df_presenter_cleaned[categorical_cols] = df_presenter_cleaned[categorical_cols].fillna(\"Unknown\")\n",
        "artist_df_cleaned[[\"PhysicalAddressCity\"]] = artist_df_cleaned[[\"PhysicalAddressCity\"]].fillna(\"Unknown\")\n",
        "\n",
        "# Filling missing numerical values with median\n",
        "numerical_cols = [\"PhysicalGeoLatitude\", \"PhysicalGeoLongitude\"]\n",
        "df_presenter_cleaned[numerical_cols] = df_presenter_cleaned[numerical_cols].fillna(df_presenter_cleaned[numerical_cols].median())\n",
        "artist_df_cleaned[numerical_cols] = artist_df_cleaned[numerical_cols].fillna(artist_df_cleaned[numerical_cols].median())\n",
        "\n",
        "# Filling missing country/state IDs with a placeholder\n",
        "df_presenter_cleaned[[\"MailingStateId\", \"MailingZip\", \"PhysicalStateId\", \"PhysicalZip\"]] = \\\n",
        "    df_presenter_cleaned[[\"MailingStateId\", \"MailingZip\", \"PhysicalStateId\", \"PhysicalZip\"]].fillna(-1)\n",
        "artist_df_cleaned[[\"MailingCountryId\", \"PhysicalAddressStateId\"]] = artist_df_cleaned[[\"MailingCountryId\", \"PhysicalAddressStateId\"]].fillna(-1)\n",
        "\n",
        "print(\"Missing values after preprocessing:\")\n",
        "print(df_presenter_cleaned.isnull().sum())\n",
        "print(artist_df_cleaned.isnull().sum())\n",
        "print(df_feedback_cleaned.isnull().sum())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Missing values after preprocessing:\nPresenterId                 0\nAgentId                     0\nAccountName                 0\nOrganizationName            0\nPresenterTypeId             0\nMailingAddress1             0\nMailingAddress2         16547\nMailingCity                 0\nMailingStateId              0\nMailingZip                  0\nMailingCountryId            0\nPhysicalAddress1            0\nPhysicalAddress2        16547\nPhysicalCity                0\nPhysicalStateId             0\nPhysicalZip                 0\nPhysicalCountryId           0\nPhysicalGeoLatitude         0\nPhysicalGeoLongitude        0\nIsActive                    0\nCreatedDate                 0\nCreatedById                 0\nParentPresenterId           0\ndtype: int64\nArtistId                          0\nName                              0\nMailingCountryId                  0\nPhysicalAddressCity               0\nPhysicalAddressStateId            0\nPhysicalGeoLatitude               0\nPhysicalGeoLongitude              0\nIsActive                          0\nIsExclusive                       0\nNationalNetPriceLowerBound    21583\nNationalNetPriceUpperBound    21584\nNationalOneOffPrice           21569\nCreatedDate                       0\nIsNational                        0\nIsNotParticipating                0\ndtype: int64\nArtistFeedbackId     0\nArtistId             0\nPresenterPortalId    0\nContractId           0\nIsNegative           0\nReviewDate           0\nFeedback             0\nCreatedDate          0\nCreatedById          0\ndtype: int64\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1740969981710
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert feedback into numerical ratings\n",
        "# Assuming IsNegative = False means a positive interaction (rating of 1), otherwise -1\n",
        "df_feedback_cleaned[\"rating\"] = np.where(df_feedback_cleaned[\"IsNegative\"] == False, 1, -1)\n",
        "\n",
        "# Create an interaction matrix\n",
        "interaction_matrix = df_feedback_cleaned.pivot_table(\n",
        "    index=\"PresenterPortalId\", columns=\"ArtistId\", values=\"rating\", fill_value=0\n",
        ")\n",
        "\n",
        "# Checking sparsity again\n",
        "sparsity = 1.0 - (interaction_matrix.count().sum() / (interaction_matrix.shape[0] * interaction_matrix.shape[1]))\n",
        "print(f\"Sparsity of Presenter-Artist Matrix: {sparsity * 100:.2f}%\")\n",
        "\n",
        "# Filter out presenters and artists with very few interactions (to reduce sparsity)\n",
        "min_interactions = 3  # Set a minimum threshold\n",
        "interaction_matrix = interaction_matrix.loc[(interaction_matrix != 0).sum(axis=1) >= min_interactions, :]\n",
        "interaction_matrix = interaction_matrix.loc[:, (interaction_matrix != 0).sum(axis=0) >= min_interactions]\n",
        "\n",
        "print(f\"Shape of filtered interaction matrix: {interaction_matrix.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sparsity of Presenter-Artist Matrix: 0.00%\nShape of filtered interaction matrix: (2, 0)\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1740970005281
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_interactions = 1  # Allowing at least one interaction\n",
        "\n",
        "interaction_matrix = df_feedback_cleaned.pivot_table(\n",
        "    index=\"PresenterPortalId\", columns=\"ArtistId\", values=\"rating\", fill_value=0\n",
        ")\n",
        "\n",
        "interaction_matrix = interaction_matrix.loc[(interaction_matrix != 0).sum(axis=1) >= min_interactions, :]\n",
        "interaction_matrix = interaction_matrix.loc[:, (interaction_matrix != 0).sum(axis=0) >= min_interactions]\n",
        "\n",
        "print(f\"Updated shape of interaction matrix: {interaction_matrix.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Updated shape of interaction matrix: (47214, 4266)\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1740970027098
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Reduce memory usage by converting types\n",
        "df_bluecardartist[\"ArtistId\"] = df_bluecardartist[\"ArtistId\"].astype(np.int32)\n",
        "df_bluecardartist[\"BlueCardId\"] = df_bluecardartist[\"BlueCardId\"].astype(np.int32)\n",
        "\n",
        "# Assign a positive implicit rating for bookings\n",
        "df_bluecardartist[\"implicit_rating\"] = 1\n",
        "\n",
        "# Create a sparse matrix for bookings\n",
        "implicit_interactions = csr_matrix((\n",
        "    df_bluecardartist[\"implicit_rating\"].values, \n",
        "    (df_bluecardartist[\"BlueCardId\"].values, df_bluecardartist[\"ArtistId\"].values)\n",
        "))\n",
        "\n",
        "# Convert interaction_matrix to a sparse matrix\n",
        "explicit_interactions = csr_matrix(interaction_matrix.values)\n",
        "\n",
        "# Ensure both matrices have the same shape by padding\n",
        "max_rows = max(explicit_interactions.shape[0], implicit_interactions.shape[0])\n",
        "max_cols = max(explicit_interactions.shape[1], implicit_interactions.shape[1])\n",
        "\n",
        "explicit_interactions.resize((max_rows, max_cols))\n",
        "implicit_interactions.resize((max_rows, max_cols))\n",
        "\n",
        "# Add explicit and implicit interactions\n",
        "final_sparse_matrix = explicit_interactions + implicit_interactions\n",
        "\n",
        "print(f\"Final sparse interaction matrix shape: {final_sparse_matrix.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Final sparse interaction matrix shape: (869540, 104195)\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1740970031210
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k\n",
        "\n",
        "# Train-test split\n",
        "from lightfm.data import Dataset\n",
        "\n",
        "# Initialize dataset object\n",
        "dataset = Dataset()\n",
        "\n",
        "# Fit dataset with user-item interactions\n",
        "dataset.fit(\n",
        "    users=np.arange(final_sparse_matrix.shape[0]), \n",
        "    items=np.arange(final_sparse_matrix.shape[1])\n",
        ")\n",
        "\n",
        "# Convert sparse interaction matrix into LightFM format\n",
        "(interactions, weights) = dataset.build_interactions(\n",
        "    [(i, j) for i, j in zip(*final_sparse_matrix.nonzero())]\n",
        ")\n",
        "\n",
        "# Create model (Warp = better for implicit data, SVD-like factorization)\n",
        "model = LightFM(loss=\"warp\")  # Alternately, use loss=\"bpr\" for SVD-like behavior\n",
        "\n",
        "# Train the model\n",
        "model.fit(interactions, epochs=10, num_threads=4)\n",
        "\n",
        "# Evaluate the model\n",
        "precision = precision_at_k(model, interactions, k=5).mean()\n",
        "print(f\"Precision at 5: {precision:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Precision at 5: 0.0959\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1740930852458
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained LightFM model\n",
        "with open(\"lightfm_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model saved successfully!\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1740930963966
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load model\n",
        "with open(\"lightfm_model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model loaded successfully!\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1740972928866
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluations Before Tuning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k\n",
        "\n",
        "# Train-test split\n",
        "from lightfm.data import Dataset\n",
        "\n",
        "# Initialize dataset object\n",
        "dataset = Dataset()\n",
        "\n",
        "# Fit dataset with user-item interactions\n",
        "dataset.fit(\n",
        "    users=np.arange(final_sparse_matrix.shape[0]), \n",
        "    items=np.arange(final_sparse_matrix.shape[1])\n",
        ")\n",
        "\n",
        "# Convert sparse interaction matrix into LightFM format\n",
        "(interactions, weights) = dataset.build_interactions(\n",
        "    [(i, j) for i, j in zip(*final_sparse_matrix.nonzero())]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1740972940594
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Evaluate the model before tuning\n",
        "print(\"\\n--- Evaluating Model Before Hyperparameter Tuning ---\")\n",
        "\n",
        "# Compute Precision@5\n",
        "precision_before = precision_at_k(model, interactions, k=5).mean()\n",
        "print(f\"Precision@5 (Before Tuning): {precision_before:.4f}\")\n",
        "\n",
        "# Compute Recall@5\n",
        "recall_before = recall_at_k(model, interactions, k=5).mean()\n",
        "print(f\"Recall@5 (Before Tuning): {recall_before:.4f}\")\n",
        "\n",
        "# Compute AUC Score\n",
        "auc_before = auc_score(model, interactions).mean()\n",
        "print(f\"AUC Score (Before Tuning): {auc_before:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n--- Evaluating Model Before Hyperparameter Tuning ---\nPrecision@5 (Before Tuning): 0.0959\nRecall@5 (Before Tuning): 0.0819\nAUC Score (Before Tuning): 0.9983\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1740966194273
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Extract non-zero actual interactions (only where users interacted with items)\n",
        "actual_rows, actual_cols = final_sparse_matrix.nonzero()\n",
        "actual_values = final_sparse_matrix.data  # Get actual ratings\n",
        "\n",
        "# Get predictions for the same (presenter, artist) pairs\n",
        "predicted_values = model.predict(actual_rows, actual_cols)\n",
        "\n",
        "# Compute RMSE on only the non-zero interactions\n",
        "rmse_before = np.sqrt(mean_squared_error(actual_values, predicted_values))\n",
        "print(f\"RMSE (Before Tuning): {rmse_before:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RMSE (Before Tuning): 1.3549\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1740966200205
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 5 presenters with most interactions\n",
        "top_presenters = np.array(final_sparse_matrix.sum(axis=1)).flatten().argsort()[-5:][::-1]\n",
        " \n",
        "print(\"Top 5 Presenters:\", top_presenters)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Top 5 Presenters: [199444 840368 816921 801776 805039]\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1740966204465
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(model, presenter_id, num_recommendations=5):\n",
        "\n",
        "    num_artists = final_sparse_matrix.shape[1]  # Total number of artists\n",
        "\n",
        "    # Ensure presenter_id is in an array\n",
        "    presenter_id_array = np.array([presenter_id] * num_artists)  # Repeat presenter ID for all artists\n",
        "    artist_id_array = np.arange(num_artists)  # Artist indices\n",
        "\n",
        "    # Generate scores for all artists\n",
        "    scores = model.predict(presenter_id_array, artist_id_array)\n",
        "\n",
        "    # Get top N recommended artists\n",
        "    top_artists = np.argsort(-scores)[:num_recommendations]\n",
        "\n",
        "    return top_artists\n",
        "\n",
        "# List of Top 5 Presenters\n",
        "top_presenters = [199444, 840368, 816921, 801776, 805039]\n",
        "\n",
        "# Get recommendations for top 5 presenters\n",
        "recommendations = {presenter: get_recommendations(model, presenter) for presenter in top_presenters}\n",
        "\n",
        "# Display results\n",
        "for presenter, artists in recommendations.items():\n",
        "    print(f\"Recommended Artists for Presenter {presenter}: {artists}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Recommended Artists for Presenter 199444: [  622  7426   687   133 16588]\nRecommended Artists for Presenter 840368: [31050 32190 30663   296 31176]\nRecommended Artists for Presenter 816921: [18325   315  2293  6542 19977]\nRecommended Artists for Presenter 801776: [14265 17586 16632 11440   794]\nRecommended Artists for Presenter 805039: [32190 31050   296 30663 31966]\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1740972940767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping of ArtistId to Name\n",
        "artist_id_to_name = dict(zip(artist_df[\"ArtistId\"], artist_df[\"Name\"]))\n",
        "\n",
        "# Function to get artist names\n",
        "def get_artist_names(artist_ids):\n",
        "    return [artist_id_to_name.get(artist_id, \"Unknown Artist\") for artist_id in artist_ids]\n",
        "\n",
        "# Get recommendations with names\n",
        "recommendations_with_names = {\n",
        "    presenter: get_artist_names(artists) for presenter, artists in recommendations.items()\n",
        "}\n",
        "\n",
        "# Display results with names\n",
        "for presenter, artist_names in recommendations_with_names.items():\n",
        "    print(f\"Recommended Artists for Presenter {presenter}: {artist_names}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Recommended Artists for Presenter 199444: ['TFC', 'TRADEMARK', 'THE GENTLEMEN & THEIR LADY', 'LIQUID PLEASURE WITH KENNY MANN', 'KLAXTON BROWN']\nRecommended Artists for Presenter 840368: ['MICHEL JONS BAND', 'WE GOT THE BEAT', 'LOOSE CHAIN', 'THE VOLTAGE BROTHERS', 'SHIMMER BAND']\nRecommended Artists for Presenter 816921: ['CIRQUE ZUMA ZUMA', 'BACKSTABBERS', \"TERRY LEE & THE GT'S\", 'THE SECOND CITY TOURING COMPANY', 'FAREWELL ANGELINA']\nRecommended Artists for Presenter 801776: ['FANTASY', 'JAVA BAND', 'HOT SAUCE', \"THE SWINGIN' RICHARDS\", 'MR. POTATO HEAD']\nRecommended Artists for Presenter 805039: ['WE GOT THE BEAT', 'MICHEL JONS BAND', 'THE VOLTAGE BROTHERS', 'LOOSE CHAIN', 'ASCENSION']\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1740966209428
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm.data import Dataset\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Recreate LightFM Dataset\n",
        "dataset = Dataset()\n",
        "\n",
        "# Fit dataset with user-item interactions\n",
        "dataset.fit(\n",
        "    users=np.arange(final_sparse_matrix.shape[0]),  # All presenter IDs\n",
        "    items=np.arange(final_sparse_matrix.shape[1])   # All artist IDs\n",
        ")\n",
        "\n",
        "# Convert sparse interaction matrix into LightFM format\n",
        "(interactions, _) = dataset.build_interactions(\n",
        "    [(i, j) for i, j in zip(*final_sparse_matrix.nonzero())]\n",
        ")\n",
        "\n",
        "print(f\"Shape of interactions matrix: {interactions.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Shape of interactions matrix: (869540, 104195)\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1740970033185
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k\n",
        "import random\n",
        "\n",
        "# Define search space\n",
        "loss_functions = [\"warp\", \"bpr\"]\n",
        "num_components_options = [10, 20, 50]\n",
        "learning_rates = [0.01, 0.05, 0.1]\n",
        "epochs = 5  # Initially low to test configurations faster\n",
        "num_threads = 4  # Use 4 threads for parallel training\n",
        "\n",
        "# Randomized Search (selects random hyperparameters)\n",
        "num_trials = 5  \n",
        "random_trials = [\n",
        "    (random.choice(loss_functions), random.choice(num_components_options), random.choice(learning_rates))\n",
        "    for _ in range(num_trials)\n",
        "]\n",
        "\n",
        "best_model = None\n",
        "best_precision = 0\n",
        "best_params = {}\n",
        "\n",
        "for loss, num_components, lr in random_trials:\n",
        "    print(f\"Training model: loss={loss}, factors={num_components}, lr={lr}\")\n",
        "\n",
        "    # Train model\n",
        "    model = LightFM(loss=loss, no_components=num_components, learning_rate=lr)\n",
        "    model.fit(interactions, epochs=epochs, num_threads=num_threads)  # Set threads to 4\n",
        "\n",
        "    # Evaluate model\n",
        "    precision = precision_at_k(model, interactions, k=5).mean()\n",
        "    print(f\"Precision@5: {precision:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if precision > best_precision:\n",
        "        best_model = model\n",
        "        best_precision = precision\n",
        "        best_params = {\"loss\": loss, \"factors\": num_components, \"lr\": lr}\n",
        "\n",
        "print(\"\\nBest Model Found:\")\n",
        "print(f\"Loss: {best_params['loss']}, Factors: {best_params['factors']}, LR: {best_params['lr']}\")\n",
        "print(f\"Best Precision@5: {best_precision:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training model: loss=bpr, factors=10, lr=0.05\nPrecision@5: 0.2140\nTraining model: loss=bpr, factors=20, lr=0.05\nPrecision@5: 0.2202\nTraining model: loss=bpr, factors=50, lr=0.01\nPrecision@5: 0.0611\nTraining model: loss=warp, factors=10, lr=0.05\nPrecision@5: 0.0777\nTraining model: loss=warp, factors=20, lr=0.1\nPrecision@5: 0.1027\n\nBest Model Found:\nLoss: bpr, Factors: 20, LR: 0.05\nBest Precision@5: 0.2202\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1740761103033
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k\n",
        "\n",
        "# Retrain the best model\n",
        "best_model = LightFM(loss=\"bpr\", no_components=20, learning_rate=0.05)\n",
        "best_model.fit(interactions, epochs=30, num_threads=4)  # Train with more epochs\n",
        "\n",
        "print(\"Model retrained successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model retrained successfully!\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1740966250896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Define the filename\n",
        "model_filename = \"lightfm_best_model.pkl\"\n",
        "\n",
        "# Save the model\n",
        "with open(model_filename, \"wb\") as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\"Model saved successfully as {model_filename}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model saved successfully as lightfm_best_model.pkl\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1740934116817
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Define the filename\n",
        "model_filename = \"lightfm_best_model.pkl\"\n",
        "\n",
        "# Load the saved model\n",
        "with open(model_filename, \"rb\") as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model loaded successfully!\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1740970067516
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Evaluating Model After Hyperparameter Tuning ---\")\n",
        "\n",
        "# Compute Precision@5\n",
        "precision_after = precision_at_k(best_model, interactions, k=5).mean()\n",
        "print(f\"Precision@5 (After Tuning): {precision_after:.4f}\")\n",
        "\n",
        "# Compute Recall@5\n",
        "recall_after = recall_at_k(best_model, interactions, k=5).mean()\n",
        "print(f\"Recall@5 (After Tuning): {recall_after:.4f}\")\n",
        "\n",
        "# Compute AUC Score\n",
        "auc_after = auc_score(best_model, interactions).mean()\n",
        "print(f\"AUC Score (After Tuning): {auc_after:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n--- Evaluating Model After Hyperparameter Tuning ---\nPrecision@5 (After Tuning): 0.3469\nRecall@5 (After Tuning): 0.4945\nAUC Score (After Tuning): 0.9962\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1740969456512
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Sample a subset of presenters to reduce memory load\n",
        "num_samples = min(5000, final_sparse_matrix.shape[0])  # Pick 5000 or total if smaller\n",
        "sampled_presenters = np.random.choice(final_sparse_matrix.shape[0], num_samples, replace=False)\n",
        "\n",
        "# Get artist IDs\n",
        "artist_ids = np.arange(final_sparse_matrix.shape[1])\n",
        "\n",
        "# Store actual and predicted ratings\n",
        "actual_ratings = []\n",
        "predicted_ratings = []\n",
        "\n",
        "# Process in batches\n",
        "batch_size = 100  # Adjust based on available memory\n",
        "\n",
        "for i in range(0, len(sampled_presenters), batch_size):\n",
        "    batch_presenters = sampled_presenters[i : i + batch_size]  # Select batch\n",
        "\n",
        "    # Convert to numpy array for consistent shape\n",
        "    batch_actual_ratings = [final_sparse_matrix[presenter].toarray().flatten() for presenter in batch_presenters]\n",
        "    batch_actual_ratings = np.array(batch_actual_ratings)\n",
        "\n",
        "    # **Predict scores using batched presenter IDs**\n",
        "    presenter_array = np.repeat(batch_presenters[:, np.newaxis], artist_ids.shape[0], axis=1)  # Expand presenters\n",
        "    batch_predicted_ratings = np.array([best_model.predict(presenter_array[j], artist_ids) for j in range(len(batch_presenters))])\n",
        "\n",
        "    # Store results\n",
        "    actual_ratings.extend(batch_actual_ratings)\n",
        "    predicted_ratings.extend(batch_predicted_ratings)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "actual_ratings = np.array(actual_ratings)\n",
        "predicted_ratings = np.array(predicted_ratings)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse_after = np.sqrt(mean_squared_error(actual_ratings.flatten(), predicted_ratings.flatten()))\n",
        "print(f\"RMSE (After Tuning): {rmse_after:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RMSE (After Tuning): 0.2542\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1740972658424
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping of ArtistId to Name\n",
        "artist_id_to_name = dict(zip(artist_df[\"ArtistId\"], artist_df[\"Name\"]))\n",
        "\n",
        "# Function to get artist names\n",
        "def get_artist_names(artist_ids):\n",
        "    return [artist_id_to_name.get(artist_id, \"Unknown Artist\") for artist_id in artist_ids]\n",
        "\n",
        "# Get recommendations with names\n",
        "recommendations_with_names = {\n",
        "    presenter: get_artist_names(artists) for presenter, artists in recommendations.items()\n",
        "}\n",
        "\n",
        "# Display results with names\n",
        "for presenter, artist_names in recommendations_with_names.items():\n",
        "    print(f\"Recommended Artists for Presenter {presenter}: {artist_names}\")\n",
        "\n",
        "def get_recommendations(model, presenter_id, num_recommendations=5):\n",
        "\n",
        "    num_artists = final_sparse_matrix.shape[1]  # Total number of artists\n",
        "\n",
        "    # Ensure presenter_id is in an array\n",
        "    presenter_id_array = np.array([presenter_id] * num_artists)  # Repeat presenter ID for all artists\n",
        "    artist_id_array = np.arange(num_artists)  # Artist indices\n",
        "\n",
        "    # Generate scores for all artists\n",
        "    scores = model.predict(presenter_id_array, artist_id_array)\n",
        "\n",
        "    # Get top N recommended artists\n",
        "    top_artists = np.argsort(-scores)[:num_recommendations]\n",
        "\n",
        "    return top_artists\n",
        "\n",
        "top_presenters = [199444, 840368, 816921, 801776, 805039]\n",
        "\n",
        "# Get recommendations for top 5 presenters using the final trained model\n",
        "final_recommendations = {presenter: get_recommendations(best_model, presenter) for presenter in top_presenters}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Recommended Artists for Presenter 199444: ['TFC', 'TRADEMARK', 'THE GENTLEMEN & THEIR LADY', 'LIQUID PLEASURE WITH KENNY MANN', 'KLAXTON BROWN']\nRecommended Artists for Presenter 840368: ['MICHEL JONS BAND', 'WE GOT THE BEAT', 'LOOSE CHAIN', 'THE VOLTAGE BROTHERS', 'SHIMMER BAND']\nRecommended Artists for Presenter 816921: ['CIRQUE ZUMA ZUMA', 'BACKSTABBERS', \"TERRY LEE & THE GT'S\", 'THE SECOND CITY TOURING COMPANY', 'FAREWELL ANGELINA']\nRecommended Artists for Presenter 801776: ['FANTASY', 'JAVA BAND', 'HOT SAUCE', \"THE SWINGIN' RICHARDS\", 'MR. POTATO HEAD']\nRecommended Artists for Presenter 805039: ['WE GOT THE BEAT', 'MICHEL JONS BAND', 'THE VOLTAGE BROTHERS', 'LOOSE CHAIN', 'ASCENSION']\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1740973285428
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"lightfm_best_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best_model, f)\n",
        "print(\"Model saved successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model saved successfully!\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1740765295579
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}